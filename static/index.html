<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title> Voice Cloning Studio</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .main-content {
            padding: 40px;
        }

        .section {
            margin-bottom: 40px;
            padding: 30px;
            border-radius: 15px;
            background: #f8f9fa;
            border: 2px solid #e9ecef;
        }

        .section h2 {
            color: #495057;
            margin-bottom: 20px;
            font-size: 1.8rem;
        }

        .form-group {
            margin-bottom: 20px;
        }

        .form-group label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #495057;
        }

        .form-group input,
        .form-group select,
        .form-group textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #dee2e6;
            border-radius: 8px;
            font-size: 16px;
            transition: border-color 0.3s;
        }

        .form-group input:focus,
        .form-group select:focus,
        .form-group textarea:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }

        .btn {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s;
            margin-right: 10px;
            margin-bottom: 10px;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }

        .btn:active {
            transform: translateY(0);
        }

        .btn-secondary {
            background: linear-gradient(45deg, #6c757d, #495057);
        }

        .btn-success {
            background: linear-gradient(45deg, #28a745, #20c997);
        }

        .btn-danger {
            background: linear-gradient(45deg, #dc3545, #c82333);
        }

        .progress {
            width: 100%;
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
            margin: 20px 0;
        }

        .progress-bar {
            height: 100%;
            background: linear-gradient(45deg, #28a745, #20c997);
            width: 0%;
            transition: width 0.3s;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: 600;
        }

        .status {
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            font-weight: 600;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status.info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }

        .voice-card {
            background: white;
            border: 2px solid #dee2e6;
            border-radius: 15px;
            padding: 20px;
            margin: 15px 0;
            transition: transform 0.2s;
        }

        .voice-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .voice-card h3 {
            color: #495057;
            margin-bottom: 10px;
        }

        .voice-card p {
            color: #6c757d;
            margin-bottom: 15px;
        }

        .audio-player {
            width: 100%;
            margin: 15px 0;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
        }

        .hidden {
            display: none;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .connections {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255,255,255,0.9);
            padding: 10px;
            border-radius: 8px;
            font-weight: 600;
        }

        .connection-status {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 5px;
        }

        .connected {
            background: #28a745;
        }        .disconnected {
            background: #dc3545;
        }

        /* Chatbot Styles */
        .chat-message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
            max-width: 80%;
        }

        .chat-message.user {
            background: #e3f2fd;
            margin-left: auto;
            text-align: right;
        }

        .chat-message.assistant {
            background: #f1f8e9;
            margin-right: auto;
        }

        .message-content {
            word-wrap: break-word;
        }

        .message-audio {
            margin-top: 8px;
        }

        .message-audio audio {
            width: 100%;
            max-width: 300px;
        }        .conversation-item {
            background: white;
            border: 2px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            cursor: pointer;
            transition: transform 0.2s;
        }

        .conversation-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .conversation-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 10px;
        }

        .conversation-header h4 {
            margin: 0;
            color: #495057;
            font-size: 1.1rem;
        }

        .conversation-date {
            font-size: 0.85rem;
            color: #6c757d;
            white-space: nowrap;
        }

        .conversation-preview {
            margin-bottom: 10px;
        }

        .last-message {
            color: #6c757d;
            font-size: 0.9rem;
            margin: 0 0 5px 0;
            line-height: 1.4;
        }

        .message-count {
            font-size: 0.8rem;
            color: #007bff;
            font-weight: 600;
        }

        .conversation-actions {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }

        .btn-small {
            padding: 5px 12px;
            font-size: 0.85rem;
            border-radius: 4px;
        }

        .conversations-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .conversations-header h3 {
            margin: 0;
            color: #495057;
        }

        .conversations-list {
            max-height: 600px;
            overflow-y: auto;
        }

        .no-conversations {
            text-align: center;
            padding: 40px 20px;
            color: #6c757d;
        }

        .conversation-item h4 {
            margin-bottom: 5px;
            color: #495057;
        }

        /* Voice Recording Styles */
        .btn.recording {
            background: #dc3545 !important;
            color: white !important;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .voice-input-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            background: #dc3545;
            border-radius: 50%;
            margin-right: 5px;
            animation: blink 1s infinite;
        }

        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }

        /* Progress indicators */
        #chatProgress {
            margin-top: 10px;
        }

        #chatStatus {
            margin-top: 10px;
            min-height: 30px;
        }
    </style>
</head>
<body>
    <div class="connections">
        <span class="connection-status disconnected" id="connectionStatus"></span>
        <span id="connectionText">Connecting...</span>
    </div>

    <div class="container">
        <div class="header">
            <h1> Voice Cloning Studio</h1>
            <p>Clone voices from 10-second samples and generate Hindi text-to-speech</p>
        </div>

        <div class="main-content">
            <!-- Upload Voice Section -->
            <div class="section" id="uploadSection">
                <h2> Upload Voice Sample</h2>
                <form id="uploadForm">
                    <div class="grid">
                        <div>
                            <div class="form-group">
                                <label for="voiceName">Voice Name *</label>
                                <input type="text" id="voiceName" required placeholder="Enter unique voice name">
                            </div>
                            <div class="form-group">
                                <label for="description">Description</label>
                                <textarea id="description" rows="3" placeholder="Describe this voice..."></textarea>
                            </div>
                            <div class="form-group">
                                <label for="language">Language</label>
                                <select id="language">
                                    <option value="hi">Hindi</option>
                                    <option value="en">English</option>
                                    <option value="other">Other</option>
                                </select>
                            </div>
                        </div>
                        <div>
                            <div class="form-group">
                                <label for="audioFile">Audio File *</label>
                                <input type="file" id="audioFile" accept=".wav,.mp3,.m4a,.flac,.ogg" required>
                            </div>
                            <div id="audioPreview" class="hidden">
                                <audio id="previewPlayer" class="audio-player" controls></audio>
                            </div>
                        </div>
                    </div>
                    <button type="submit" class="btn"> Upload and Process Voice</button>
                </form>
                <div class="progress hidden" id="uploadProgress">
                    <div class="progress-bar" id="uploadProgressBar">0%</div>
                </div>
                <div id="uploadStatus"></div>
            </div>

            <!-- Generate Speech Section -->
            <div class="section" id="generateSection">
                <h2>üéµ Generate Speech</h2>
                <form id="generateForm">
                    <div class="grid">
                        <div>
                            <div class="form-group">
                                <label for="selectedVoice">Select Voice</label>
                                <select id="selectedVoice">
                                    <option value="">Select a voice...</option>
                                </select>
                            </div>                            <div class="form-group">
                                <label for="textInput">Hinglish Text to Convert *</label>
                                <textarea id="textInput" rows="6" required placeholder="‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•ã‡§∏‡•ç‡§§, ‡§Ø‡§π‡§æ‡§Å ‡§§‡•ã ‡§Æ‡•å‡§∏‡§Æ ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§∏‡§æ‡§´‡§º ‡§î‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§Ø‡§∞ ‡§π‡•à, ‡§Ü‡§™ ‡§¨‡§§‡§æ‡§ì ‡§ï‡§ø ‡§µ‡§π‡§æ‡§Å ‡§π‡§æ‡§≤ ‡§ö‡§æ‡§≤ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à‡•§ ‡§Ü‡§∂‡§æ ‡§π‡•à ‡§Æ‡•á‡§∞‡•Ä ‡§ï‡§ø ‡§Ü‡§™‡§ï‡§æ ‡§π‡§æ‡§≤ ‡§≠‡•Ä ‡§†‡•Ä‡§ï ‡§π‡•Ä ‡§π‡•ã‡§ó‡§æ‡•§ and i really do hope that the weather is fine at your end."></textarea>                                <small style="color: #6c757d; font-size: 0.9em;">
                                     Mix Hindi and English naturally - the AI will handle both languages seamlessly!
                                </small>
                                <div style="margin-top: 10px;">
                                    <button type="button" class="btn btn-small" onclick="setExampleText(1)" style="margin-right: 10px; padding: 8px 16px; font-size: 0.9em;">Example 1</button>
                                    <button type="button" class="btn btn-small" onclick="setExampleText(2)" style="margin-right: 10px; padding: 8px 16px; font-size: 0.9em;">Example 2</button>                                    <button type="button" class="btn btn-small" onclick="setExampleText(3)" style="padding: 8px 16px; font-size: 0.9em;">Example 3</button>
                                </div>
                            </div>
                            <div class="form-group">
                                <label>
                                    <input type="checkbox" id="realtimeMode" style="margin-right: 8px;">
                                     Real-time Streaming Mode
                                </label>
                                <small style="color: #6c757d; font-size: 0.9em; display: block; margin-top: 5px;">
                                    Generate and play audio in real-time chunks as they're processed
                                </small>
                            </div>
                        </div>
                        <div>
                            <div class="form-group">
                                <label>Voice Details</label>
                                <div id="voiceDetails" class="voice-card">
                                    <p>Select a voice to see details</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <button type="submit" class="btn"> Generate Speech</button>
                </form>
                <div class="progress hidden" id="generateProgress">
                    <div class="progress-bar" id="generateProgressBar">0%</div>
                </div>
                <div id="generateStatus"></div>                <div id="generatedAudio" class="hidden">
                    <h3>Generated Audio:</h3>
                    <audio id="generatedPlayer" class="audio-player" controls></audio>
                    <br>
                    <a id="downloadLink" class="btn btn-success" download> Download Audio</a>
                </div>
                
                <!-- Real-time Audio Streaming Container -->
                <div id="realtimeAudioContainer" class="hidden">
                    <h3>üéµ Real-time Audio Stream:</h3>
                    <div id="realtimeStatus" style="margin-bottom: 15px; padding: 10px; background: #e3f2fd; border-radius: 8px;">
                        <strong>Status:</strong> <span id="realtimeStatusText">Ready</span>
                    </div>
                    <div id="audioChunks" style="margin-bottom: 15px;">
                        <!-- Audio chunks will be added here dynamically -->
                    </div>
                    <div style="display: flex; gap: 10px;">
                        <button id="playAllChunks" class="btn" onclick="app.playAllChunks()"> Play All</button>
                        <button id="stopAllChunks" class="btn" onclick="app.stopAllChunks()"> Stop All</button>
                        <button id="downloadAllChunks" class="btn btn-success" onclick="app.downloadAllChunks()">üì• Download All</button>
                    </div>
                </div>
            </div>            <!-- Voice Library Section -->
            <div class="section" id="librarySection">
                <h2> Voice Library</h2>
                <button id="refreshVoices" class="btn btn-secondary"> Refresh</button>
                <div id="voicesList"></div>
            </div>            <!-- Hindi Chatbot Section -->            <div class="section" id="chatbotSection">
                <h2>ü§ñ Hinglish Chatbot (Natural Conversations)</h2>
                <p>Chat with AI in any language and get natural Hinglish responses! Voice generation uses pure Hindi for best quality.</p>
                
                <!-- Chatbot Selection -->
                <div class="form-group">
                    <label for="chatbotProvider">Select Chatbot Provider</label>
                    <select id="chatbotProvider" style="background: linear-gradient(45deg, #667eea, #764ba2); color: white; font-weight: bold;">
                        <option value="openai">üöÄ OpenAI GPT-3.5-turbo (Recommended)</option>
                        <option value="gemini">üåü Google Gemini</option>
                    </select>
                    <small style="color: #6c757d; margin-top: 5px; display: block;">
                        Both chatbots respond in pure Hindi for better voice quality
                    </small>
                </div>
                
                <!-- Conversation Controls -->
                <div class="grid">
                    <div>
                        <div class="form-group">
                            <label for="chatVoice">Select Voice for AI Responses</label>
                            <select id="chatVoice">
                                <option value="">No voice (text only)</option>
                            </select>
                        </div>
                    </div>
                    <div>
                        <div class="form-group">
                            <label>Conversation</label>
                            <div style="display: flex; gap: 10px;">
                                <button id="newConversation" class="btn">üÜï New Chat</button>
                                <button id="loadConversations" class="btn btn-secondary">üìÇ Load Chats</button>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Chat Container -->
                <div id="chatContainer" class="hidden">
                    <div id="chatHeader" style="padding: 15px; background: #f8f9fa; border-radius: 8px; margin-bottom: 20px;">
                        <h3 id="chatTitle">New Conversation</h3>
                        <p><span id="chatLanguage">Hinglish</span> ‚Ä¢ <span id="chatMessageCount">0 messages</span></p>
                    </div>                    <!-- Chat Messages -->
                    <div id="chatMessages" style="max-height: 400px; overflow-y: auto; border: 2px solid #dee2e6; border-radius: 8px; padding: 15px; margin-bottom: 20px; background: white;">
                        <div id="welcomeMessage" class="chat-message assistant">
                            <div class="message-content">
                                <strong id="aiAssistantName">AI Assistant:</strong> <span id="welcomeText">‡§®‡§Æ‡§∏‡•ç‡§§‡•á! I'm ready to chat with you in Hinglish. ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? How can I help you today?</span>
                            </div>
                        </div>
                    </div>

                    <!-- Message Input -->
                    <div class="form-group">
                        <div style="display: flex; gap: 10px;">
                            <textarea id="chatInput" rows="2" placeholder="Type your message in Hinglish... ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ English ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç!" style="flex: 1;"></textarea>
                            <div style="display: flex; flex-direction: column; gap: 5px;">
                                <button id="sendMessage" class="btn"> Send</button>
                                <button id="voiceInput" class="btn btn-secondary"> Voice</button>
                            </div>
                        </div>
                    </div>

                    <!-- Example Hinglish Messages -->
                    <div style="margin-top: 15px;">
                        <label>Quick Examples:</label>                        <div style="display: flex; flex-wrap: wrap; gap: 5px; margin-top: 8px;">
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Namaste! Aap kaise hain?')">Namaste! Aap kaise hain?</button>
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Weather kaisa hai today?')">Weather kaisa hai today?</button>
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Main bahut khush hun')">Main bahut khush hun</button>
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Tell me a joke yaar!')">Tell me a joke yaar!</button>
                        </div>
                    </div>

                    <div id="chatStatus"></div>
                    <div class="progress hidden" id="chatProgress">
                        <div class="progress-bar" id="chatProgressBar">0%</div>
                    </div>
                </div>

                <!-- Conversations List -->
                <div id="conversationsList" class="hidden">
                    <h3>Your Conversations</h3>
                    <div id="conversationsContainer"></div>
                </div>
            </div>
        </div>
    </div>

    <script>        class VoiceCloningApp {
            constructor() {
                this.ws = null;
                this.voices = [];
                this.isConnected = false;
                this.baseUrl = this.getBaseUrl();
                this.init();
            }

            getBaseUrl() {
                // Dynamically get the base URL for API calls
                const protocol = window.location.protocol;
                const host = window.location.host;
                return `${protocol}//${host}`;
            }init() {
                this.connectWebSocket();
                this.setupEventListeners();
                this.loadVoices();
                this.initChatbot();
            }            connectWebSocket() {
                const clientId = 'web_client_' + Math.random().toString(36).substr(2, 9);
                
                // Dynamically determine WebSocket URL based on current location
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const host = window.location.host; // This will be your Render URL
                const wsUrl = `${protocol}//${host}/ws/${clientId}`;
                
                console.log('Connecting to WebSocket:', wsUrl);
                this.ws = new WebSocket(wsUrl);

                this.ws.onopen = () => {
                    this.isConnected = true;
                    this.updateConnectionStatus();
                    console.log('WebSocket connected');
                    this.sendMessage({ type: 'list_voices' });
                };

                this.ws.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    this.handleWebSocketMessage(message);
                };

                this.ws.onclose = () => {
                    this.isConnected = false;
                    this.updateConnectionStatus();
                    console.log('WebSocket disconnected');
                    setTimeout(() => this.connectWebSocket(), 3000);
                };

                this.ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                };
            }

            updateConnectionStatus() {
                const statusElement = document.getElementById('connectionStatus');
                const textElement = document.getElementById('connectionText');
                
                if (this.isConnected) {
                    statusElement.className = 'connection-status connected';
                    textElement.textContent = 'Connected';
                } else {
                    statusElement.className = 'connection-status disconnected';
                    textElement.textContent = 'Disconnected';
                }
            }

            sendMessage(message) {
                if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.ws.send(JSON.stringify(message));
                }
            }            handleWebSocketMessage(message) {
                switch (message.type) {
                    case 'voice_list':
                        this.voices = message.voices;
                        this.updateVoicesList();
                        this.updateVoiceSelect();
                        this.updateChatVoiceSelect();
                        break;
                    case 'voice_added':
                        this.showStatus('uploadStatus', `Voice '${message.voice_name}' added successfully!`, 'success');
                        this.loadVoices();
                        break;
                    case 'voice_deleted':
                        this.showStatus('librarySection', `Voice '${message.voice_name}' deleted successfully!`, 'success');
                        this.loadVoices();
                        break;
                    case 'progress':
                        this.updateProgress('generateProgress', 'generateProgressBar', message.progress, message.message);
                        break;                    case 'speech_generated':
                        this.handleSpeechGenerated(message);
                        break;
                    case 'realtime_started':
                        this.handleRealtimeStarted(message);
                        break;
                    case 'realtime_progress':
                        this.handleRealtimeProgress(message);
                        break;
                    case 'audio_chunk':
                        this.handleAudioChunk(message);
                        break;
                    case 'realtime_complete':
                        this.handleRealtimeComplete(message);
                        break;
                    // Chatbot message types
                    case 'conversation_started':
                        this.handleConversationStarted(message);
                        break;
                    case 'chat_response':
                        this.handleChatResponse(message);
                        break;
                    case 'chat_progress':
                        this.updateProgress('chatProgress', 'chatProgressBar', message.progress, message.message);
                        break;
                    case 'conversations_list':
                        this.handleConversationsList(message);
                        break;                    case 'conversation_details':
                        this.handleConversationDetails(message);
                        break;
                    // Speech-to-text message types
                    case 'stt_progress':
                        this.updateProgress('chatProgress', 'chatProgressBar', message.progress, message.message);
                        break;
                    case 'stt_result':
                        this.handleSpeechToTextResult(message);
                        break;
                    case 'error':
                        this.showStatus('generateStatus', `Error: ${message.message}`, 'error');
                        this.showStatus('chatStatus', `Error: ${message.message}`, 'error');
                        this.hideProgress('chatProgress');
                        this.resetVoiceUI();
                        break;
                }
            }

            setupEventListeners() {
                // Upload form
                document.getElementById('uploadForm').addEventListener('submit', (e) => {
                    e.preventDefault();
                    this.uploadVoice();
                });

                // Generate form
                document.getElementById('generateForm').addEventListener('submit', (e) => {
                    e.preventDefault();
                    this.generateSpeech();
                });

                // Audio file preview
                document.getElementById('audioFile').addEventListener('change', (e) => {
                    this.previewAudio(e.target.files[0]);
                });

                // Voice selection
                document.getElementById('selectedVoice').addEventListener('change', (e) => {
                    this.showVoiceDetails(e.target.value);
                });

                // Refresh voices
                document.getElementById('refreshVoices').addEventListener('click', () => {
                    this.loadVoices();
                });
            }

            previewAudio(file) {
                if (file) {
                    const url = URL.createObjectURL(file);
                    const preview = document.getElementById('audioPreview');
                    const player = document.getElementById('previewPlayer');
                    
                    player.src = url;
                    preview.classList.remove('hidden');
                }
            }

            async uploadVoice() {
                const form = document.getElementById('uploadForm');
                const formData = new FormData();
                
                formData.append('voice_name', document.getElementById('voiceName').value);
                formData.append('description', document.getElementById('description').value);
                formData.append('language', document.getElementById('language').value);
                formData.append('audio_file', document.getElementById('audioFile').files[0]);

                try {
                    this.showProgress('uploadProgress', 'uploadProgressBar', 0, 'Uploading...');
                    
                    const response = await fetch('/upload_voice', {
                        method: 'POST',
                        body: formData
                    });

                    const result = await response.json();
                    
                    if (result.success) {
                        this.showStatus('uploadStatus', 'Voice uploaded successfully!', 'success');
                        form.reset();
                        document.getElementById('audioPreview').classList.add('hidden');
                        this.hideProgress('uploadProgress');
                        this.loadVoices();
                    } else {
                        this.showStatus('uploadStatus', `Upload failed: ${result.message}`, 'error');
                        this.hideProgress('uploadProgress');
                    }
                } catch (error) {
                    this.showStatus('uploadStatus', `Upload error: ${error.message}`, 'error');
                    this.hideProgress('uploadProgress');
                }
            }            generateSpeech() {
                const voiceName = document.getElementById('selectedVoice').value;
                const text = document.getElementById('textInput').value;
                const realtimeMode = document.getElementById('realtimeMode').checked;

                if (!voiceName || !text) {
                    this.showStatus('generateStatus', 'Please select a voice and enter text', 'error');
                    return;
                }

                // Clear previous results
                document.getElementById('generatedAudio').classList.add('hidden');
                document.getElementById('realtimeAudioContainer').classList.add('hidden');
                
                if (realtimeMode) {
                    // Initialize real-time container
                    this.initializeRealtimeContainer();
                    
                    this.sendMessage({
                        type: 'generate_speech_realtime',
                        voice_name: voiceName,
                        text: text
                    });
                } else {
                    this.sendMessage({
                        type: 'generate_speech',
                        voice_name: voiceName,
                        text: text
                    });
                }

                this.showProgress('generateProgress', 'generateProgressBar', 20, 'Starting generation...');
            }

            handleSpeechGenerated(message) {
                this.hideProgress('generateProgress');
                this.showStatus('generateStatus', 'Speech generated successfully!', 'success');
                
                const audioContainer = document.getElementById('generatedAudio');
                const player = document.getElementById('generatedPlayer');
                const downloadLink = document.getElementById('downloadLink');
                
                const audioUrl = `${this.baseUrl}${message.audio_file}`;
                player.src = audioUrl;
                downloadLink.href = audioUrl;
                downloadLink.download = `generated_${message.voice_name}.wav`;
                
                audioContainer.classList.remove('hidden');
            }

            async loadVoices() {
                try {
                    const response = await fetch('/voices');
                    const data = await response.json();
                    
                    if (data.success) {
                        this.voices = data.voices;
                        this.updateVoicesList();
                        this.updateVoiceSelect();
                    }
                } catch (error) {
                    console.error('Error loading voices:', error);
                }
            }

            updateVoiceSelect() {
                const select = document.getElementById('selectedVoice');
                select.innerHTML = '<option value="">Select a voice...</option>';
                
                this.voices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.voice_name;
                    option.textContent = voice.voice_name;
                    select.appendChild(option);
                });
            }

            updateVoicesList() {
                const container = document.getElementById('voicesList');
                
                if (this.voices.length === 0) {
                    container.innerHTML = '<p>No voices available. Upload your first voice sample!</p>';
                    return;
                }

                container.innerHTML = this.voices.map(voice => `
                    <div class="voice-card">
                        <h3>${voice.voice_name}</h3>
                        <p>${voice.metadata?.description || 'No description'}</p>
                        <p><strong>Language:</strong> ${voice.metadata?.language || 'Unknown'}</p>
                        <p><strong>Created:</strong> ${new Date(voice.created_at).toLocaleDateString()}</p>
                        <button class="btn" onclick="app.selectVoiceForGeneration('${voice.voice_name}')">üé§ Use for Generation</button>
                        <button class="btn btn-danger" onclick="app.deleteVoice('${voice.voice_name}')">üóëÔ∏è Delete</button>
                    </div>
                `).join('');
            }

            selectVoiceForGeneration(voiceName) {
                document.getElementById('selectedVoice').value = voiceName;
                this.showVoiceDetails(voiceName);
                document.getElementById('generateSection').scrollIntoView({ behavior: 'smooth' });
            }

            async showVoiceDetails(voiceName) {
                const container = document.getElementById('voiceDetails');
                
                if (!voiceName) {
                    container.innerHTML = '<p>Select a voice to see details</p>';
                    return;
                }

                try {
                    const response = await fetch(`/voice/${voiceName}`);
                    const data = await response.json();
                    
                    if (data.success) {
                        const profile = data.voice_profile;
                        const metadata = profile.metadata || {};
                        
                        container.innerHTML = `
                            <h3>${voiceName}</h3>
                            <p><strong>Description:</strong> ${metadata.description || 'No description'}</p>
                            <p><strong>Language:</strong> ${metadata.language || 'Unknown'}</p>
                            <p><strong>Created:</strong> ${new Date(profile.created_at).toLocaleDateString()}</p>
                            <p><strong>File:</strong> ${metadata.original_filename || 'Unknown'}</p>
                        `;
                    }
                } catch (error) {
                    container.innerHTML = '<p>Error loading voice details</p>';
                }
            }

            async deleteVoice(voiceName) {
                if (!confirm(`Are you sure you want to delete voice '${voiceName}'?`)) {
                    return;
                }

                try {
                    const response = await fetch(`/voice/${voiceName}`, {
                        method: 'DELETE'
                    });

                    const result = await response.json();
                    
                    if (result.success) {
                        this.loadVoices();
                    } else {
                        alert(`Failed to delete voice: ${result.message}`);
                    }
                } catch (error) {
                    alert(`Error deleting voice: ${error.message}`);
                }
            }

            showStatus(containerId, message, type) {
                const container = document.getElementById(containerId);
                const statusDiv = document.createElement('div');
                statusDiv.className = `status ${type}`;
                statusDiv.textContent = message;
                
                // Remove existing status
                const existing = container.querySelector('.status');
                if (existing) {
                    existing.remove();
                }
                
                container.appendChild(statusDiv);
                
                // Auto-remove after 5 seconds
                setTimeout(() => {
                    if (statusDiv.parentNode) {
                        statusDiv.remove();
                    }
                }, 5000);
            }

            showProgress(containerId, barId, progress, message) {
                const container = document.getElementById(containerId);
                const bar = document.getElementById(barId);
                
                container.classList.remove('hidden');
                bar.style.width = `${progress}%`;
                bar.textContent = message || `${progress}%`;
            }            updateProgress(containerId, barId, progress, message) {
                const bar = document.getElementById(barId);
                bar.style.width = `${progress}%`;
                bar.textContent = message || `${progress}%`;
            }

            hideProgress(containerId) {
                const container = document.getElementById(containerId);
                container.classList.add('hidden');
            }            // === CHATBOT METHODS ===
            initChatbot() {
                this.currentConversationId = null;
                this.isRecording = false;
                this.audioChunks = [];
                this.mediaRecorder = null;
                this.recordingTimeout = null;
                this.silenceDetector = null;
                this.autoMode = false; // Automatic conversation mode
                this.setupChatEventListeners();
                this.updateChatVoiceSelect();
            }            setupChatEventListeners() {
                // Chatbot provider change
                document.getElementById('chatbotProvider').addEventListener('change', (e) => {
                    this.updateChatbotProvider(e.target.value);
                });

                // New conversation button
                document.getElementById('newConversation').addEventListener('click', () => {
                    this.startNewConversation();
                });

                // Load conversations button
                document.getElementById('loadConversations').addEventListener('click', () => {
                    this.toggleConversationsList();
                });

                // Send message button
                document.getElementById('sendMessage').addEventListener('click', () => {
                    this.sendChatMessage();
                });

                // Voice input button
                document.getElementById('voiceInput').addEventListener('click', () => {
                    this.startVoiceInput();
                });

                // Enter key in chat input
                document.getElementById('chatInput').addEventListener('keypress', (e) => {
                    if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        this.sendChatMessage();
                    }
                });
            }

            updateChatVoiceSelect() {
                const select = document.getElementById('chatVoice');
                select.innerHTML = '<option value="">No voice (text only)</option>';
                
                this.voices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.voice_name;
                    option.textContent = voice.voice_name;
                    select.appendChild(option);
                });            }

            updateChatbotProvider(provider) {
                const aiNameElement = document.getElementById('aiAssistantName');
                const welcomeTextElement = document.getElementById('welcomeText');
                
                if (provider === 'openai') {
                    aiNameElement.textContent = 'OpenAI GPT-3.5:';
                    welcomeTextElement.textContent = '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! I\'m OpenAI GPT-3.5-turbo, ready to chat with you in Hinglish. ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? How can I help you today?';
                } else if (provider === 'gemini') {
                    aiNameElement.textContent = 'Google Gemini:';
                    welcomeTextElement.textContent = '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! I\'m Google Gemini, ready to chat with you in Hinglish. ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? How can I help you today?';
                }
                
                // Show status message about provider change
                this.showStatus('chatStatus', `Switched to ${provider === 'openai' ? 'OpenAI GPT-3.5-turbo' : 'Google Gemini'} chatbot`, 'success');
                
                // If there's an active conversation, you might want to restart it or notify the user
                if (this.currentConversationId) {
                    this.showStatus('chatStatus', 'Provider changed. You may want to start a new conversation for consistency.', 'info');
                }
            }

            startNewConversation() {
                this.sendMessage({
                    type: 'start_conversation',
                    title: 'New Hinglish Chat',
                    language: 'hinglish',
                    metadata: { created_from: 'web_interface' }
                });
            }            sendChatMessage() {
                const input = document.getElementById('chatInput');
                const message = input.value.trim();
                const voiceName = document.getElementById('chatVoice').value;
                const chatbotProvider = document.getElementById('chatbotProvider').value;

                if (!message) return;
                if (!this.currentConversationId) {
                    this.showStatus('chatStatus', 'Please start a new conversation first', 'error');
                    return;
                }

                // Clear input
                input.value = '';

                // Add user message to chat
                this.addChatMessage('user', message);

                // Send to server
                this.sendMessage({
                    type: 'chat_message',
                    conversation_id: this.currentConversationId,
                    message: message,
                    voice_name: voiceName,
                    chatbot_provider: chatbotProvider
                });

                this.showProgress('chatProgress', 'chatProgressBar', 20, 'Sending message...');            }            addChatMessage(role, content, audioFile = null) {
                const messagesContainer = document.getElementById('chatMessages');
                const messageDiv = document.createElement('div');
                messageDiv.className = `chat-message ${role}`;

                let audioHtml = '';
                if (audioFile) {
                    // Fix audio file URL - ensure it's a proper HTTP URL
                    let audioUrl = audioFile;                    if (audioFile.startsWith('file:///')) {
                        // Extract just the filename from file:// URL
                        const filename = audioFile.split('/').pop();
                        audioUrl = `${this.baseUrl}/download/${filename}`;
                    } else if (!audioFile.startsWith('http://') && !audioFile.startsWith('https://')) {
                        // If it's a relative path, construct proper server URL
                        const filename = audioFile.split('\\').pop().split('/').pop(); // Handle both / and \ separators
                        audioUrl = `${this.baseUrl}/download/${filename}`;
                    }
                    
                    // Create unique ID for this audio element
                    const audioId = `audio_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
                    audioHtml = `
                        <div class="message-audio">
                            <audio id="${audioId}" controls>
                                <source src="${audioUrl}" type="audio/wav">
                                Your browser does not support the audio element.
                            </audio>
                        </div>
                    `;
                }

                messageDiv.innerHTML = `
                    <div class="message-content">
                        <strong>${role === 'user' ? 'You' : 'AI Assistant'}:</strong> ${content}
                        ${audioHtml}
                    </div>
                `;

                messagesContainer.appendChild(messageDiv);
                messagesContainer.scrollTop = messagesContainer.scrollHeight;

                // Auto-play AI assistant audio responses
                if (audioFile && role === 'assistant') {
                    setTimeout(() => {
                        const audioElement = messageDiv.querySelector('audio');
                        if (audioElement) {
                            this.playAIResponseAndStartRecording(audioElement);
                        }
                    }, 500); // Small delay to ensure audio element is ready
                }

                // Update message count
                const messageCount = messagesContainer.children.length - 1; // Exclude welcome message
                document.getElementById('chatMessageCount').textContent = `${messageCount} messages`;
            }

            toggleConversationsList() {
                const listContainer = document.getElementById('conversationsList');
                const chatContainer = document.getElementById('chatContainer');

                if (listContainer.classList.contains('hidden')) {
                    // Show conversations list
                    this.loadConversations();
                    listContainer.classList.remove('hidden');
                    chatContainer.classList.add('hidden');
                } else {
                    // Hide conversations list
                    listContainer.classList.add('hidden');
                    if (this.currentConversationId) {
                        chatContainer.classList.remove('hidden');
                    }
                }
            }

            loadConversations() {
                this.sendMessage({
                    type: 'list_conversations',
                    limit: 20
                });
            }

            setExample(text) {
                document.getElementById('chatInput').value = text;
            }            startVoiceInput() {
                if (!this.currentConversationId) {
                    this.showStatus('chatStatus', 'Please start a new conversation first', 'error');
                    return;
                }

                if (this.isRecording) {
                    this.stopVoiceRecording();
                    return;
                }

                // Manual voice input (not automatic)
                this.autoMode = false;
                this.startVoiceRecording();
            }

            async startVoiceRecording() {
                try {
                    // Request microphone permission
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    this.audioChunks = [];
                    this.isRecording = true;

                    // Update UI
                    const voiceButton = document.getElementById('voiceInput');
                    voiceButton.textContent = ' Stop';
                    voiceButton.classList.add('recording');
                    this.showStatus('chatStatus', 'Recording... Speak in Hinglish', 'info');

                    // Handle data available
                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                    };

                    // Handle recording stop
                    this.mediaRecorder.onstop = () => {
                        this.processVoiceRecording();
                    };

                    // Start recording
                    this.mediaRecorder.start();

                    // Auto-stop after 30 seconds
                    this.recordingTimeout = setTimeout(() => {
                        if (this.isRecording) {
                            this.stopVoiceRecording();
                        }
                    }, 30000);

                } catch (error) {
                    console.error('Error starting voice recording:', error);
                    this.showStatus('chatStatus', 'Error: Could not access microphone', 'error');
                    this.resetVoiceUI();
                }
            }

            stopVoiceRecording() {
                if (!this.isRecording || !this.mediaRecorder) {
                    return;
                }

                this.isRecording = false;
                this.mediaRecorder.stop();
                
                // Stop all tracks
                this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clear timeout
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                }

                this.showStatus('chatStatus', 'Processing audio...', 'info');
            }

            async processVoiceRecording() {
                try {
                    // Create blob from audio chunks
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    
                    // Convert to base64
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const uint8Array = new Uint8Array(arrayBuffer);
                    const base64Audio = btoa(String.fromCharCode(...uint8Array));

                    // Send to server for speech-to-text
                    this.sendMessage({
                        type: 'speech_to_text',
                        audio_data: base64Audio,
                        format: 'webm',
                        language: 'hinglish'
                    });

                    this.showProgress('chatProgress', 'chatProgressBar', 30, 'Converting speech to text...');

                } catch (error) {
                    console.error('Error processing voice recording:', error);
                    this.showStatus('chatStatus', 'Error processing audio', 'error');
                } finally {
                    this.resetVoiceUI();
                }
            }

            resetVoiceUI() {
                const voiceButton = document.getElementById('voiceInput');
                voiceButton.textContent = ' Voice';
                voiceButton.classList.remove('recording');
                this.isRecording = false;
                this.audioChunks = [];
                
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                    this.recordingTimeout = null;
                }
            }

            // === AUTOMATIC CONVERSATION METHODS ===
            
            async playAIResponseAndStartRecording(audioElement) {
                try {
                    console.log(' Auto-playing AI response...');
                    this.showStatus('chatStatus', ' Playing AI response...', 'info');
                    
                    // Play the audio response
                    await audioElement.play();
                    
                    // Wait for audio to finish playing
                    return new Promise((resolve) => {
                        audioElement.onended = () => {
                            console.log(' AI response finished playing');
                            this.showStatus('chatStatus', ' Ready to listen...', 'info');
                            
                            // Start automatic voice recording after a short delay
                            setTimeout(() => {
                                this.startAutomaticVoiceRecording();
                                resolve();
                            }, 1000); // 1 second delay before starting recording
                        };
                        
                        audioElement.onerror = () => {
                            console.error(' Error playing AI response');
                            this.showStatus('chatStatus', 'Error playing response', 'error');
                            resolve();
                        };
                    });
                    
                } catch (error) {
                    console.error('Error in auto-play:', error);
                    this.showStatus('chatStatus', 'Could not auto-play response', 'error');
                }
            }

            async startAutomaticVoiceRecording() {
                if (!this.currentConversationId) {
                    return;
                }

                try {
                    console.log(' Starting automatic voice recording...');
                    
                    // Request microphone permission
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    this.audioChunks = [];
                    this.isRecording = true;
                    this.autoMode = true;

                    // Update UI for automatic recording
                    const voiceButton = document.getElementById('voiceInput');
                    voiceButton.textContent = ' Auto Recording';
                    voiceButton.classList.add('recording');
                    this.showStatus('chatStatus', ' Auto-recording... Speak now (3s silence stops)', 'info');

                    // Set up silence detection
                    this.setupSilenceDetection(stream);

                    // Handle data available
                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                    };

                    // Handle recording stop
                    this.mediaRecorder.onstop = () => {
                        this.processAutomaticVoiceRecording();
                    };

                    // Start recording
                    this.mediaRecorder.start();

                    // Failsafe: stop after 30 seconds max
                    this.recordingTimeout = setTimeout(() => {
                        if (this.isRecording) {
                            console.log('‚è∞ Maximum recording time reached');
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 30000);

                } catch (error) {
                    console.error('Error starting automatic voice recording:', error);
                    this.showStatus('chatStatus', 'Error: Could not start automatic recording', 'error');
                    this.resetVoiceUI();
                }
            }

            setupSilenceDetection(stream) {
                try {
                    // Create audio context for silence detection
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    const analyser = audioContext.createAnalyser();
                    
                    analyser.fftSize = 256;
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    
                    source.connect(analyser);
                    
                    let silenceStartTime = null;
                    const silenceThreshold = 30; // Threshold for silence (adjust as needed)
                    const silenceTimeout = 3000; // 3 seconds of silence
                    
                    const checkAudioLevel = () => {
                        if (!this.isRecording) return;
                        
                        analyser.getByteFrequencyData(dataArray);
                        
                        // Calculate average volume
                        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                        
                        if (average < silenceThreshold) {
                            // Silence detected
                            if (silenceStartTime === null) {
                                silenceStartTime = Date.now();
                                console.log(' Silence detected, starting timer...');
                            } else if (Date.now() - silenceStartTime >= silenceTimeout) {
                                console.log(' 3 seconds of silence detected, stopping recording');
                                this.stopAutomaticVoiceRecording();
                                return;
                            }
                        } else {
                            // Sound detected, reset silence timer
                            if (silenceStartTime !== null) {
                                console.log(' Sound detected, resetting silence timer');
                                silenceStartTime = null;
                            }
                        }
                        
                        // Continue checking
                        requestAnimationFrame(checkAudioLevel);
                    };
                    
                    // Start monitoring
                    checkAudioLevel();
                    
                    // Store references for cleanup
                    this.silenceDetector = {
                        audioContext,
                        source,
                        analyser,
                        cleanup: () => {
                            try {
                                source.disconnect();
                                audioContext.close();
                            } catch (e) {
                                console.log('Cleanup warning:', e);
                            }
                        }
                    };
                    
                } catch (error) {
                    console.error('Error setting up silence detection:', error);
                    // Fallback: just use timer-based recording
                    setTimeout(() => {
                        if (this.isRecording) {
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 10000); // 10 seconds fallback
                }
            }

            stopAutomaticVoiceRecording() {
                if (!this.isRecording || !this.mediaRecorder) {
                    return;
                }

                console.log('Stopping automatic voice recording...');
                this.isRecording = false;
                this.mediaRecorder.stop();
                
                // Stop all tracks
                this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clean up silence detector
                if (this.silenceDetector) {
                    this.silenceDetector.cleanup();
                    this.silenceDetector = null;
                }
                
                // Clear timeout
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                }

                this.showStatus('chatStatus', 'Processing your voice...', 'info');
            }

            async processAutomaticVoiceRecording() {
                try {
                    console.log(' Processing automatic voice recording...');
                    
                    // Create blob from audio chunks
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    
                    // Check if we have meaningful audio (not just silence)
                    if (audioBlob.size < 1000) { // Less than 1KB likely means no speech
                        console.log(' Recording too short, likely no speech detected');
                        this.showStatus('chatStatus', 'No speech detected. Try speaking louder.', 'warning');
                        this.resetVoiceUI();
                        return;
                    }
                    
                    // Convert to base64
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const uint8Array = new Uint8Array(arrayBuffer);
                    const base64Audio = btoa(String.fromCharCode(...uint8Array));

                    // Send to server for speech-to-text
                    this.sendMessage({
                        type: 'speech_to_text',
                        audio_data: base64Audio,
                        format: 'webm',
                        language: 'hinglish'
                    });

                    this.showProgress('chatProgress', 'chatProgressBar', 30, 'Converting speech to text...');

                } catch (error) {
                    console.error('Error processing automatic voice recording:', error);
                    this.showStatus('chatStatus', 'Error processing voice', 'error');
                } finally {
                    this.resetVoiceUI();
                }
            }

            handleSpeechToTextResult(message) {
                this.hideProgress('chatProgress');
                
                if (message.transcript && message.transcript.trim()) {
                    console.log(' Speech transcribed:', message.transcript);
                    
                    // In automatic mode, send the message immediately
                    if (this.autoMode) {
                        // Add transcribed text as user message and send immediately
                        this.addChatMessage('user', message.transcript);
                        
                        // Send to server for AI response
                        const voiceName = document.getElementById('chatVoice').value;
                        this.sendMessage({
                            type: 'chat_message',
                            conversation_id: this.currentConversationId,
                            message: message.transcript,
                            voice_name: voiceName
                        });
                        
                        const confidence = Math.round(message.confidence * 100);
                        this.showStatus('chatStatus', `Message sent! Confidence: ${confidence}%`, 'success');
                        this.showProgress('chatProgress', 'chatProgressBar', 20, 'Getting AI response...');
                    } else {
                        // Manual mode: add to input for editing
                        const chatInput = document.getElementById('chatInput');
                        const currentText = chatInput.value.trim();
                        const newText = currentText ? `${currentText} ${message.transcript}` : message.transcript;
                        chatInput.value = newText;
                        
                        const confidence = Math.round(message.confidence * 100);
                        this.showStatus('chatStatus', `Voice transcribed! Confidence: ${confidence}%`, 'success');
                        chatInput.focus();
                        
                        if (confirm('Send this message now?\n\n"' + message.transcript + '"')) {
                            this.sendChatMessage();
                        }
                    }
                } else {
                    this.showStatus('chatStatus', 'Could not understand speech. Please try again.', 'error');
                }
                
                // Reset auto mode flag
                this.autoMode = false;
            }

            // Modified existing method to handle both manual and automatic modes
            startVoiceInput() {
                if (!this.currentConversationId) {
                    this.showStatus('chatStatus', 'Please start a new conversation first', 'error');
                    return;
                }

                if (this.isRecording) {
                    this.stopVoiceRecording();
                    return;
                }

                // Manual voice input (not automatic)
                this.autoMode = false;
                this.startVoiceRecording();
            }

            // === AUTOMATIC CONVERSATION METHODS ===
            
            async playAIResponseAndStartRecording(audioElement) {
                try {
                    console.log(' Auto-playing AI response...');
                    this.showStatus('chatStatus', ' Playing AI response...', 'info');
                    
                    // Play the audio response
                    await audioElement.play();
                    
                    // Wait for audio to finish playing
                    return new Promise((resolve) => {
                        audioElement.onended = () => {
                            console.log(' AI response finished playing');
                            this.showStatus('chatStatus', ' Ready to listen...', 'info');
                            
                            // Start automatic voice recording after a short delay
                            setTimeout(() => {
                                this.startAutomaticVoiceRecording();
                                resolve();
                            }, 1000); // 1 second delay before starting recording
                        };
                        
                        audioElement.onerror = () => {
                            console.error(' Error playing AI response');
                            this.showStatus('chatStatus', 'Error playing response', 'error');
                            resolve();
                        };
                    });
                    
                } catch (error) {
                    console.error('Error in auto-play:', error);
                    this.showStatus('chatStatus', 'Could not auto-play response', 'error');
                }
            }

            async startAutomaticVoiceRecording() {
                if (!this.currentConversationId) {
                    return;
                }

                try {
                    console.log(' Starting automatic voice recording...');
                    
                    // Request microphone permission
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    this.audioChunks = [];
                    this.isRecording = true;
                    this.autoMode = true;

                    // Update UI for automatic recording
                    const voiceButton = document.getElementById('voiceInput');
                    voiceButton.textContent = ' Auto Recording';
                    voiceButton.classList.add('recording');
                    this.showStatus('chatStatus', ' Auto-recording... Speak now (3s silence stops)', 'info');

                    // Set up silence detection
                    this.setupSilenceDetection(stream);

                    // Handle data available
                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                    };

                    // Handle recording stop
                    this.mediaRecorder.onstop = () => {
                        this.processAutomaticVoiceRecording();
                    };

                    // Start recording
                    this.mediaRecorder.start();

                    // Failsafe: stop after 30 seconds max
                    this.recordingTimeout = setTimeout(() => {
                        if (this.isRecording) {
                            console.log(' Maximum recording time reached');
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 30000);

                } catch (error) {
                    console.error('Error starting automatic voice recording:', error);
                    this.showStatus('chatStatus', 'Error: Could not start automatic recording', 'error');
                    this.resetVoiceUI();
                }
            }

            setupSilenceDetection(stream) {
                try {
                    // Create audio context for silence detection
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    const analyser = audioContext.createAnalyser();
                    
                    analyser.fftSize = 256;
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    
                    source.connect(analyser);
                    
                    let silenceStartTime = null;
                    const silenceThreshold = 30; // Threshold for silence (adjust as needed)
                    const silenceTimeout = 3000; // 3 seconds of silence
                    
                    const checkAudioLevel = () => {
                        if (!this.isRecording) return;
                        
                        analyser.getByteFrequencyData(dataArray);
                        
                        // Calculate average volume
                        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                        
                        if (average < silenceThreshold) {
                            // Silence detected
                            if (silenceStartTime === null) {
                                silenceStartTime = Date.now();
                                console.log(' Silence detected, starting timer...');
                            } else if (Date.now() - silenceStartTime >= silenceTimeout) {
                                console.log(' 3 seconds of silence detected, stopping recording');
                                this.stopAutomaticVoiceRecording();
                                return;
                            }
                        } else {
                            // Sound detected, reset silence timer
                            if (silenceStartTime !== null) {
                                console.log(' Sound detected, resetting silence timer');
                                silenceStartTime = null;
                            }
                        }
                        
                        // Continue checking
                        requestAnimationFrame(checkAudioLevel);
                    };
                    
                    // Start monitoring
                    checkAudioLevel();
                    
                    // Store references for cleanup
                    this.silenceDetector = {
                        audioContext,
                        source,
                        analyser,
                        cleanup: () => {
                            try {
                                source.disconnect();
                                audioContext.close();
                            } catch (e) {
                                console.log('Cleanup warning:', e);
                            }
                        }
                    };
                    
                } catch (error) {
                    console.error('Error setting up silence detection:', error);
                    // Fallback: just use timer-based recording
                    setTimeout(() => {
                        if (this.isRecording) {
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 10000); // 10 seconds fallback
                }
            }

            stopAutomaticVoiceRecording() {
                if (!this.isRecording || !this.mediaRecorder) {
                    return;
                }

                console.log(' Stopping automatic voice recording...');
                this.isRecording = false;
                this.mediaRecorder.stop();
                
                // Stop all tracks
                this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clean up silence detector
                if (this.silenceDetector) {
                    this.silenceDetector.cleanup();
                    this.silenceDetector = null;
                }
                
                // Clear timeout
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                }                this.showStatus('chatStatus', 'Processing your voice...', 'info');
            }

            // === MISSING WEBSOCKET HANDLER METHODS ===

            handleConversationStarted(message) {
                console.log(' Conversation started:', message);
                if (message.conversation_id) {
                    this.currentConversationId = message.conversation_id;
                    this.showStatus('chatStatus', 'New conversation started', 'success');
                    
                    // Show chat interface
                    document.getElementById('chatContainer').classList.remove('hidden');
                    document.getElementById('conversationsList').classList.add('hidden');
                    
                    // Focus on chat input
                    document.getElementById('chatInput').focus();
                }
            }            handleChatResponse(message) {
                console.log(' Chat response received:', message);
                
                // Handle WebSocket chat response format
                if (message.assistant_message) {
                    // Add user message to chat if provided
                    if (message.user_message) {
                        this.addChatMessage('user', message.user_message);
                    }
                    
                    // Add AI response to chat with audio
                    this.addChatMessage('assistant', message.assistant_message, message.audio_file);
                      // Handle automatic mode - play audio and start recording
                    if (this.autoMode && message.audio_file) {
                        // Fix audio file URL for automatic playback
                        let audioUrl = message.audio_file;                        if (message.audio_file.startsWith('file:///')) {
                            const filename = message.audio_file.split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        } else if (!message.audio_file.startsWith('http://') && !message.audio_file.startsWith('https://')) {
                            const filename = message.audio_file.split('\\').pop().split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        }
                        const audioElement = new Audio(audioUrl);
                        this.playAIResponseAndStartRecording(audioElement);
                    }
                    
                    this.showStatus('chatStatus', 'Response received', 'success');
                } else if (message.success && message.response) {
                    // Legacy format support
                    this.addChatMessage('ai', message.response, message.audio_url);
                      if (this.autoMode && message.audio_url) {
                        // Fix audio file URL for automatic playback
                        let audioUrl = message.audio_url;                        if (message.audio_url.startsWith('file:///')) {
                            const filename = message.audio_url.split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        } else if (!message.audio_url.startsWith('http://') && !message.audio_url.startsWith('https://')) {
                            const filename = message.audio_url.split('\\').pop().split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        }
                        const audioElement = new Audio(audioUrl);
                        this.playAIResponseAndStartRecording(audioElement);
                    }
                    
                    this.showStatus('chatStatus', 'Response received', 'success');
                } else {
                    this.showStatus('chatStatus', message.message || 'Failed to get response', 'error');
                }
                
                this.hideProgress('chatProgress');            }

            handleConversationsList(message) {
                console.log('üìã Conversations list received:', message);
                
                const container = document.getElementById('conversationsContainer');
                const conversations = message.conversations || [];
                
                if (conversations.length > 0) {
                    container.innerHTML = `
                        <div class="conversations-header">
                            <h3>üìã Previous Conversations (${conversations.length})</h3>
                            <button class="btn btn-primary" onclick="app.toggleConversationsList()">
                                ‚Üê Back to Chat
                            </button>
                        </div>
                        <div class="conversations-list">                            ${conversations.map(conv => `
                                <div class="conversation-item" onclick="app.loadConversationDetails('${conv.id}')">
                                    <div class="conversation-header">
                                        <h4>${conv.title || 'Untitled Conversation'}</h4>
                                        <span class="conversation-date">${new Date(conv.created_at).toLocaleDateString('en-IN', {
                                            year: 'numeric',
                                            month: 'short',
                                            day: 'numeric',
                                            hour: '2-digit',
                                            minute: '2-digit'
                                        })}</span>
                                    </div>
                                    <div class="conversation-preview">
                                        <p class="last-message">${(conv.last_message || 'No messages yet').substring(0, 100)}${(conv.last_message || '').length > 100 ? '...' : ''}</p>
                                        <span class="message-count">${conv.message_count || 0} messages</span>
                                    </div>
                                    <div class="conversation-actions">
                                        <button class="btn btn-small btn-primary" onclick="event.stopPropagation(); app.loadConversationDetails('${conv.id}')">
                                            üí¨ Continue
                                        </button>
                                        <button class="btn btn-small btn-danger" onclick="event.stopPropagation(); app.deleteConversation('${conv.id}')">
                                            üóëÔ∏è Delete
                                        </button>
                                    </div>
                                </div>
                            `).join('')}
                        </div>
                    `;
                } else {
                    container.innerHTML = `
                        <div class="conversations-header">
                            <h3>üìã No Previous Conversations</h3>
                            <button class="btn btn-primary" onclick="app.toggleConversationsList()">
                                ‚Üê Back to Chat
                            </button>
                        </div>
                        <div class="no-conversations">
                            <p>No previous conversations found.</p>
                            <p>Start a new conversation to begin chatting!</p>
                        </div>
                    `;
                }
                
                this.showStatus('chatStatus', `Found ${conversations.length} previous conversations`, 'success');
            }            handleConversationDetails(message) {
                console.log('üí¨ Loading conversation details:', message);
                
                // Hide the loading progress bar first
                this.hideProgress('chatProgress');
                
                if (!message.conversation || !message.messages) {
                    this.showStatus('chatStatus', 'Error loading conversation details', 'error');
                    return;
                }
                  const conversation = message.conversation;
                const messages = message.messages;
                
                // Set current conversation
                this.currentConversationId = conversation.id;
                
                // Update conversation info
                document.getElementById('chatMessageCount').textContent = `${messages.length} messages`;
                
                // Clear and rebuild messages
                const messagesContainer = document.getElementById('chatMessages');
                messagesContainer.innerHTML = `
                    <div class="chat-message assistant welcome">
                        <div class="message-content">
                            <strong>üìã Loaded Conversation:</strong> ${conversation.title || 'Previous Chat'}
                            <br><small>Started: ${new Date(conversation.created_at).toLocaleString('en-IN')}</small>
                        </div>
                    </div>
                `;
                
                // Add all messages from the conversation
                messages.forEach(msg => {
                    const role = msg.role === 'user' ? 'user' : 'assistant';
                    const content = msg.content || msg.message_text;
                    const audioFile = msg.audio_file || null;
                    
                    this.addChatMessage(role, content, audioFile);
                });
                
                // Show chat container and hide conversations list
                document.getElementById('chatContainer').classList.remove('hidden');
                document.getElementById('conversationsList').classList.add('hidden');
                
                // Scroll to bottom
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
                
                this.showStatus('chatStatus', `Loaded conversation with ${messages.length} messages`, 'success');
            }

            loadConversationDetails(conversationId) {
                console.log('üîç Loading conversation details for:', conversationId);
                
                this.sendMessage({
                    type: 'get_conversation',
                    conversation_id: conversationId
                });
                
                this.showProgress('chatProgress', 'chatProgressBar', 30, 'Loading conversation...');
            }

            deleteConversation(conversationId) {
                if (!confirm('Are you sure you want to delete this conversation? This action cannot be undone.')) {
                    return;
                }
                
                console.log('üóëÔ∏è Deleting conversation:', conversationId);
                
                this.sendMessage({
                    type: 'delete_conversation',
                    conversation_id: conversationId
                });
                
                this.showStatus('chatStatus', 'Deleting conversation...', 'info');
                  // Reload conversations list
                setTimeout(() => {
                    this.loadConversations();
                }, 1000);
            }

            handleRealtimeComplete(message) {
                console.log(' Realtime generation complete:', message);
                
                if (message.success) {
                    this.showStatus('generateStatus', 'Speech generated successfully!', 'success');
                    
                    if (message.audio_url) {
                        // Show audio player
                        const audioPlayer = document.getElementById('generatedAudio');
                        const audioContainer = document.getElementById('audioResult');
                        
                        audioPlayer.src = message.audio_url;
                        audioContainer.classList.remove('hidden');
                        
                        // Auto-play if enabled
                        if (this.autoPlayEnabled) {
                            audioPlayer.play();
                        }
                    }
                } else {
                    this.showStatus('generateStatus', message.message || 'Generation failed', 'error');
                }
                
                this.hideProgress('generateProgress');
            }

            handleAudioChunk(message) {
                console.log(' Audio chunk received:', message);
                // Handle streaming audio chunks if needed for realtime playback
                if (message.chunk_data && this.streamingAudio) {
                    // Implementation for streaming audio playback
                    // This would be used for realtime audio streaming
                }
            }

            // Helper method to load a specific conversation
            loadConversation(conversationId) {
                this.sendMessage({
                    type: 'get_conversation',
                    conversation_id: conversationId
                });
            }
        }

        // Initialize app
        const app = new VoiceCloningApp();

        // Example text function for Hinglish samples
        function setExampleText(exampleNumber) {
            const textInput = document.getElementById('textInput');
            const examples = {
                1: "‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•ã‡§∏‡•ç‡§§, ‡§Ø‡§π‡§æ‡§Å ‡§§‡•ã ‡§Æ‡•å‡§∏‡§Æ ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§∏‡§æ‡§´‡§º ‡§î‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§Ø‡§∞ ‡§π‡•à, ‡§Ü‡§™ ‡§¨‡§§‡§æ‡§ì ‡§ï‡§ø ‡§µ‡§π‡§æ‡§Å ‡§π‡§æ‡§≤ ‡§ö‡§æ‡§≤ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à‡•§ ‡§Ü‡§∂‡§æ ‡§π‡•à ‡§Æ‡•á‡§∞‡•Ä ‡§ï‡§ø ‡§Ü‡§™‡§ï‡§æ ‡§π‡§æ‡§≤ ‡§≠‡•Ä ‡§†‡•Ä‡§ï ‡§π‡•Ä ‡§π‡•ã‡§ó‡§æ‡•§ and i really do hope that the weather is fine at your end.",
                2: "‡§Ü‡§ú ‡§ï‡§æ ‡§¶‡§ø‡§® ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à ‡§Ø‡§æ‡§∞, weather is really nice today. ‡§Æ‡•à‡§Ç‡§®‡•á ‡§∏‡•Å‡§¨‡§π ‡§ú‡•â‡§ó‡§ø‡§Ç‡§ó ‡§ï‡•Ä and then had a great breakfast. ‡§Ö‡§¨ ‡§§‡•ã ‡§¨‡§∏ office ‡§ú‡§æ‡§®‡§æ ‡§π‡•à ‡§î‡§∞ ‡§´‡§ø‡§∞ evening ‡§Æ‡•á‡§Ç friends ‡§ï‡•á ‡§∏‡§æ‡§• movie ‡§¶‡•á‡§ñ‡§®‡•á ‡§ú‡§æ‡§®‡§æ ‡§π‡•à‡•§",
                3: "Hi ‡§≠‡§æ‡§à, ‡§ï‡•à‡§∏‡•á ‡§π‡•ã ‡§Ü‡§™? I hope ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§†‡•Ä‡§ï ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§®‡§æ ‡§•‡§æ ‡§ï‡§ø tomorrow ‡§ï‡•Ä meeting postpone ‡§π‡•ã ‡§ó‡§à ‡§π‡•à, so we can reschedule it for next week. Let me know ‡§ú‡§¨ ‡§Ü‡§™‡§ï‡§æ time free ‡§π‡•ã‡•§"
            };
            
            if (examples[exampleNumber]) {
                textInput.value = examples[exampleNumber];
                textInput.focus();
            }
        }
    </script>
</body>
</html>
