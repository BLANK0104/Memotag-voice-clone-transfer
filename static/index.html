<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title> Voice Cloning Studio</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .main-content {
            padding: 40px;
        }

        .section {
            margin-bottom: 40px;
            padding: 30px;
            border-radius: 15px;
            background: #f8f9fa;
            border: 2px solid #e9ecef;
        }

        .section h2 {
            color: #495057;
            margin-bottom: 20px;
            font-size: 1.8rem;
        }

        .form-group {
            margin-bottom: 20px;
        }

        .form-group label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #495057;
        }

        .form-group input,
        .form-group select,
        .form-group textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #dee2e6;
            border-radius: 8px;
            font-size: 16px;
            transition: border-color 0.3s;
        }

        .form-group input:focus,
        .form-group select:focus,
        .form-group textarea:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }

        .btn {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s;
            margin-right: 10px;
            margin-bottom: 10px;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }

        .btn:active {
            transform: translateY(0);
        }

        .btn-secondary {
            background: linear-gradient(45deg, #6c757d, #495057);
        }

        .btn-success {
            background: linear-gradient(45deg, #28a745, #20c997);
        }

        .btn-danger {
            background: linear-gradient(45deg, #dc3545, #c82333);
        }

        .progress {
            width: 100%;
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
            margin: 20px 0;
        }

        .progress-bar {
            height: 100%;
            background: linear-gradient(45deg, #28a745, #20c997);
            width: 0%;
            transition: width 0.3s;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: 600;
        }

        .status {
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            font-weight: 600;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status.info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }

        .voice-card {
            background: white;
            border: 2px solid #dee2e6;
            border-radius: 15px;
            padding: 20px;
            margin: 15px 0;
            transition: transform 0.2s;
        }

        .voice-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .voice-card h3 {
            color: #495057;
            margin-bottom: 10px;
        }

        .voice-card p {
            color: #6c757d;
            margin-bottom: 15px;
        }

        .audio-player {
            width: 100%;
            margin: 15px 0;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
        }

        .hidden {
            display: none;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .connections {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255,255,255,0.9);
            padding: 10px;
            border-radius: 8px;
            font-weight: 600;
        }

        .connection-status {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 5px;
        }

        .connected {
            background: #28a745;
        }        .disconnected {
            background: #dc3545;
        }

        /* Chatbot Styles */
        .chat-message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
            max-width: 80%;
        }

        .chat-message.user {
            background: #e3f2fd;
            margin-left: auto;
            text-align: right;
        }

        .chat-message.assistant {
            background: #f1f8e9;
            margin-right: auto;
        }

        .message-content {
            word-wrap: break-word;
        }

        .message-audio {
            margin-top: 8px;
        }

        .message-audio audio {
            width: 100%;
            max-width: 300px;
        }        .conversation-item {
            background: white;
            border: 2px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            cursor: pointer;
            transition: transform 0.2s;
        }

        .conversation-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .conversation-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 10px;
        }

        .conversation-header h4 {
            margin: 0;
            color: #495057;
            font-size: 1.1rem;
        }

        .conversation-date {
            font-size: 0.85rem;
            color: #6c757d;
            white-space: nowrap;
        }

        .conversation-preview {
            margin-bottom: 10px;
        }

        .last-message {
            color: #6c757d;
            font-size: 0.9rem;
            margin: 0 0 5px 0;
            line-height: 1.4;
        }

        .message-count {
            font-size: 0.8rem;
            color: #007bff;
            font-weight: 600;
        }

        .conversation-actions {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }

        .btn-small {
            padding: 5px 12px;
            font-size: 0.85rem;
            border-radius: 4px;
        }

        .conversations-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .conversations-header h3 {
            margin: 0;
            color: #495057;
        }

        .conversations-list {
            max-height: 600px;
            overflow-y: auto;
        }

        .no-conversations {
            text-align: center;
            padding: 40px 20px;
            color: #6c757d;
        }

        .conversation-item h4 {
            margin-bottom: 5px;
            color: #495057;
        }

        /* Voice Recording Styles */
        .btn.recording {
            background: #dc3545 !important;
            color: white !important;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .voice-input-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            background: #dc3545;
            border-radius: 50%;
            margin-right: 5px;
            animation: blink 1s infinite;
        }

        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }

        /* Progress indicators */
        #chatProgress {
            margin-top: 10px;
        }

        #chatStatus {
            margin-top: 10px;
            min-height: 30px;
        }
    </style>
</head>
<body>
    <div class="connections">
        <span class="connection-status disconnected" id="connectionStatus"></span>
        <span id="connectionText">Connecting...</span>
    </div>

    <div class="container">
        <div class="header">
            <h1> Voice Cloning Studio</h1>
            <p>Clone voices from 10-second samples and generate Hindi text-to-speech</p>
        </div>

        <div class="main-content">
            <!-- Upload Voice Section -->
            <div class="section" id="uploadSection">
                <h2> Upload Voice Sample</h2>
                <form id="uploadForm">
                    <div class="grid">
                        <div>
                            <div class="form-group">
                                <label for="voiceName">Voice Name *</label>
                                <input type="text" id="voiceName" required placeholder="Enter unique voice name">
                            </div>
                            <div class="form-group">
                                <label for="description">Description</label>
                                <textarea id="description" rows="3" placeholder="Describe this voice..."></textarea>
                            </div>
                            <div class="form-group">
                                <label for="language">Language</label>
                                <select id="language">
                                    <option value="hi">Hindi</option>
                                    <option value="en">English</option>
                                    <option value="other">Other</option>
                                </select>
                            </div>
                        </div>
                        <div>
                            <div class="form-group">
                                <label for="audioFile">Audio File *</label>
                                <input type="file" id="audioFile" accept=".wav,.mp3,.m4a,.flac,.ogg" required>
                            </div>
                            <div id="audioPreview" class="hidden">
                                <audio id="previewPlayer" class="audio-player" controls></audio>
                            </div>
                        </div>
                    </div>
                    <button type="submit" class="btn"> Upload and Process Voice</button>
                </form>
                <div class="progress hidden" id="uploadProgress">
                    <div class="progress-bar" id="uploadProgressBar">0%</div>
                </div>
                <div id="uploadStatus"></div>
            </div>

            <!-- Generate Speech Section -->
            <div class="section" id="generateSection">
                <h2>🎵 Generate Speech</h2>
                <form id="generateForm">
                    <div class="grid">
                        <div>
                            <div class="form-group">
                                <label for="selectedVoice">Select Voice</label>
                                <select id="selectedVoice">
                                    <option value="">Select a voice...</option>
                                </select>
                            </div>                            <div class="form-group">
                                <label for="textInput">Hinglish Text to Convert *</label>
                                <textarea id="textInput" rows="6" required placeholder="नमस्ते दोस्त, यहाँ तो मौसम बिल्कुल साफ़ और क्लियर है, आप बताओ कि वहाँ हाल चाल कैसा है। आशा है मेरी कि आपका हाल भी ठीक ही होगा। and i really do hope that the weather is fine at your end."></textarea>                                <small style="color: #6c757d; font-size: 0.9em;">
                                     Mix Hindi and English naturally - the AI will handle both languages seamlessly!
                                </small>
                                <div style="margin-top: 10px;">
                                    <button type="button" class="btn btn-small" onclick="setExampleText(1)" style="margin-right: 10px; padding: 8px 16px; font-size: 0.9em;">Example 1</button>
                                    <button type="button" class="btn btn-small" onclick="setExampleText(2)" style="margin-right: 10px; padding: 8px 16px; font-size: 0.9em;">Example 2</button>                                    <button type="button" class="btn btn-small" onclick="setExampleText(3)" style="padding: 8px 16px; font-size: 0.9em;">Example 3</button>
                                </div>
                            </div>
                            <div class="form-group">
                                <label>
                                    <input type="checkbox" id="realtimeMode" style="margin-right: 8px;">
                                     Real-time Streaming Mode
                                </label>
                                <small style="color: #6c757d; font-size: 0.9em; display: block; margin-top: 5px;">
                                    Generate and play audio in real-time chunks as they're processed
                                </small>
                            </div>
                        </div>
                        <div>
                            <div class="form-group">
                                <label>Voice Details</label>
                                <div id="voiceDetails" class="voice-card">
                                    <p>Select a voice to see details</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <button type="submit" class="btn"> Generate Speech</button>
                </form>
                <div class="progress hidden" id="generateProgress">
                    <div class="progress-bar" id="generateProgressBar">0%</div>
                </div>
                <div id="generateStatus"></div>                <div id="generatedAudio" class="hidden">
                    <h3>Generated Audio:</h3>
                    <audio id="generatedPlayer" class="audio-player" controls></audio>
                    <br>
                    <a id="downloadLink" class="btn btn-success" download> Download Audio</a>
                </div>
                
                <!-- Real-time Audio Streaming Container -->
                <div id="realtimeAudioContainer" class="hidden">
                    <h3>🎵 Real-time Audio Stream:</h3>
                    <div id="realtimeStatus" style="margin-bottom: 15px; padding: 10px; background: #e3f2fd; border-radius: 8px;">
                        <strong>Status:</strong> <span id="realtimeStatusText">Ready</span>
                    </div>
                    <div id="audioChunks" style="margin-bottom: 15px;">
                        <!-- Audio chunks will be added here dynamically -->
                    </div>
                    <div style="display: flex; gap: 10px;">
                        <button id="playAllChunks" class="btn" onclick="app.playAllChunks()"> Play All</button>
                        <button id="stopAllChunks" class="btn" onclick="app.stopAllChunks()"> Stop All</button>
                        <button id="downloadAllChunks" class="btn btn-success" onclick="app.downloadAllChunks()">📥 Download All</button>
                    </div>
                </div>
            </div>            <!-- Voice Library Section -->
            <div class="section" id="librarySection">
                <h2> Voice Library</h2>
                <button id="refreshVoices" class="btn btn-secondary"> Refresh</button>
                <div id="voicesList"></div>
            </div>            <!-- Hindi Chatbot Section -->            <div class="section" id="chatbotSection">
                <h2>🤖 Hinglish Chatbot (Natural Conversations)</h2>
                <p>Chat with AI in any language and get natural Hinglish responses! Voice generation uses pure Hindi for best quality.</p>
                
                <!-- Chatbot Selection -->
                <div class="form-group">
                    <label for="chatbotProvider">Select Chatbot Provider</label>
                    <select id="chatbotProvider" style="background: linear-gradient(45deg, #667eea, #764ba2); color: white; font-weight: bold;">
                        <option value="openai">🚀 OpenAI GPT-3.5-turbo (Recommended)</option>
                        <option value="gemini">🌟 Google Gemini</option>
                    </select>
                    <small style="color: #6c757d; margin-top: 5px; display: block;">
                        Both chatbots respond in pure Hindi for better voice quality
                    </small>
                </div>
                
                <!-- Conversation Controls -->
                <div class="grid">
                    <div>
                        <div class="form-group">
                            <label for="chatVoice">Select Voice for AI Responses</label>
                            <select id="chatVoice">
                                <option value="">No voice (text only)</option>
                            </select>
                        </div>
                    </div>
                    <div>
                        <div class="form-group">
                            <label>Conversation</label>
                            <div style="display: flex; gap: 10px;">
                                <button id="newConversation" class="btn">🆕 New Chat</button>
                                <button id="loadConversations" class="btn btn-secondary">📂 Load Chats</button>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Chat Container -->
                <div id="chatContainer" class="hidden">
                    <div id="chatHeader" style="padding: 15px; background: #f8f9fa; border-radius: 8px; margin-bottom: 20px;">
                        <h3 id="chatTitle">New Conversation</h3>
                        <p><span id="chatLanguage">Hinglish</span> • <span id="chatMessageCount">0 messages</span></p>
                    </div>                    <!-- Chat Messages -->
                    <div id="chatMessages" style="max-height: 400px; overflow-y: auto; border: 2px solid #dee2e6; border-radius: 8px; padding: 15px; margin-bottom: 20px; background: white;">
                        <div id="welcomeMessage" class="chat-message assistant">
                            <div class="message-content">
                                <strong id="aiAssistantName">AI Assistant:</strong> <span id="welcomeText">नमस्ते! I'm ready to chat with you in Hinglish. आप कैसे हैं? How can I help you today?</span>
                            </div>
                        </div>
                    </div>

                    <!-- Message Input -->
                    <div class="form-group">
                        <div style="display: flex; gap: 10px;">
                            <textarea id="chatInput" rows="2" placeholder="Type your message in Hinglish... हिंदी और English दोनों में लिख सकते हैं!" style="flex: 1;"></textarea>
                            <div style="display: flex; flex-direction: column; gap: 5px;">
                                <button id="sendMessage" class="btn"> Send</button>
                                <button id="voiceInput" class="btn btn-secondary"> Voice</button>
                            </div>
                        </div>
                    </div>

                    <!-- Example Hinglish Messages -->
                    <div style="margin-top: 15px;">
                        <label>Quick Examples:</label>                        <div style="display: flex; flex-wrap: wrap; gap: 5px; margin-top: 8px;">
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Namaste! Aap kaise hain?')">Namaste! Aap kaise hain?</button>
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Weather kaisa hai today?')">Weather kaisa hai today?</button>
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Main bahut khush hun')">Main bahut khush hun</button>
                            <button class="btn" style="font-size: 12px; padding: 5px 10px;" onclick="app.setExample('Tell me a joke yaar!')">Tell me a joke yaar!</button>
                        </div>
                    </div>

                    <div id="chatStatus"></div>
                    <div class="progress hidden" id="chatProgress">
                        <div class="progress-bar" id="chatProgressBar">0%</div>
                    </div>
                </div>

                <!-- Conversations List -->
                <div id="conversationsList" class="hidden">
                    <h3>Your Conversations</h3>
                    <div id="conversationsContainer"></div>
                </div>
            </div>
        </div>
    </div>

    <script>        class VoiceCloningApp {
            constructor() {
                this.ws = null;
                this.voices = [];
                this.isConnected = false;
                this.baseUrl = this.getBaseUrl();
                this.init();
            }

            getBaseUrl() {
                // Dynamically get the base URL for API calls
                const protocol = window.location.protocol;
                const host = window.location.host;
                return `${protocol}//${host}`;
            }init() {
                this.connectWebSocket();
                this.setupEventListeners();
                this.loadVoices();
                this.initChatbot();
            }            connectWebSocket() {
                const clientId = 'web_client_' + Math.random().toString(36).substr(2, 9);
                
                // Dynamically determine WebSocket URL based on current location
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const host = window.location.host; // This will be your Render URL
                const wsUrl = `${protocol}//${host}/ws/${clientId}`;
                
                console.log('Connecting to WebSocket:', wsUrl);
                this.ws = new WebSocket(wsUrl);

                this.ws.onopen = () => {
                    this.isConnected = true;
                    this.updateConnectionStatus();
                    console.log('WebSocket connected');
                    this.sendMessage({ type: 'list_voices' });
                };

                this.ws.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    this.handleWebSocketMessage(message);
                };

                this.ws.onclose = () => {
                    this.isConnected = false;
                    this.updateConnectionStatus();
                    console.log('WebSocket disconnected');
                    setTimeout(() => this.connectWebSocket(), 3000);
                };

                this.ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                };
            }

            updateConnectionStatus() {
                const statusElement = document.getElementById('connectionStatus');
                const textElement = document.getElementById('connectionText');
                
                if (this.isConnected) {
                    statusElement.className = 'connection-status connected';
                    textElement.textContent = 'Connected';
                } else {
                    statusElement.className = 'connection-status disconnected';
                    textElement.textContent = 'Disconnected';
                }
            }

            sendMessage(message) {
                if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.ws.send(JSON.stringify(message));
                }
            }            handleWebSocketMessage(message) {
                switch (message.type) {
                    case 'voice_list':
                        this.voices = message.voices;
                        this.updateVoicesList();
                        this.updateVoiceSelect();
                        this.updateChatVoiceSelect();
                        break;
                    case 'voice_added':
                        this.showStatus('uploadStatus', `Voice '${message.voice_name}' added successfully!`, 'success');
                        this.loadVoices();
                        break;
                    case 'voice_deleted':
                        this.showStatus('librarySection', `Voice '${message.voice_name}' deleted successfully!`, 'success');
                        this.loadVoices();
                        break;
                    case 'progress':
                        this.updateProgress('generateProgress', 'generateProgressBar', message.progress, message.message);
                        break;                    case 'speech_generated':
                        this.handleSpeechGenerated(message);
                        break;
                    case 'realtime_started':
                        this.handleRealtimeStarted(message);
                        break;
                    case 'realtime_progress':
                        this.handleRealtimeProgress(message);
                        break;
                    case 'audio_chunk':
                        this.handleAudioChunk(message);
                        break;
                    case 'realtime_complete':
                        this.handleRealtimeComplete(message);
                        break;
                    // Chatbot message types
                    case 'conversation_started':
                        this.handleConversationStarted(message);
                        break;
                    case 'chat_response':
                        this.handleChatResponse(message);
                        break;
                    case 'chat_progress':
                        this.updateProgress('chatProgress', 'chatProgressBar', message.progress, message.message);
                        break;
                    case 'conversations_list':
                        this.handleConversationsList(message);
                        break;                    case 'conversation_details':
                        this.handleConversationDetails(message);
                        break;
                    // Speech-to-text message types
                    case 'stt_progress':
                        this.updateProgress('chatProgress', 'chatProgressBar', message.progress, message.message);
                        break;
                    case 'stt_result':
                        this.handleSpeechToTextResult(message);
                        break;
                    case 'error':
                        this.showStatus('generateStatus', `Error: ${message.message}`, 'error');
                        this.showStatus('chatStatus', `Error: ${message.message}`, 'error');
                        this.hideProgress('chatProgress');
                        this.resetVoiceUI();
                        break;
                }
            }

            setupEventListeners() {
                // Upload form
                document.getElementById('uploadForm').addEventListener('submit', (e) => {
                    e.preventDefault();
                    this.uploadVoice();
                });

                // Generate form
                document.getElementById('generateForm').addEventListener('submit', (e) => {
                    e.preventDefault();
                    this.generateSpeech();
                });

                // Audio file preview
                document.getElementById('audioFile').addEventListener('change', (e) => {
                    this.previewAudio(e.target.files[0]);
                });

                // Voice selection
                document.getElementById('selectedVoice').addEventListener('change', (e) => {
                    this.showVoiceDetails(e.target.value);
                });

                // Refresh voices
                document.getElementById('refreshVoices').addEventListener('click', () => {
                    this.loadVoices();
                });
            }

            previewAudio(file) {
                if (file) {
                    const url = URL.createObjectURL(file);
                    const preview = document.getElementById('audioPreview');
                    const player = document.getElementById('previewPlayer');
                    
                    player.src = url;
                    preview.classList.remove('hidden');
                }
            }

            async uploadVoice() {
                const form = document.getElementById('uploadForm');
                const formData = new FormData();
                
                formData.append('voice_name', document.getElementById('voiceName').value);
                formData.append('description', document.getElementById('description').value);
                formData.append('language', document.getElementById('language').value);
                formData.append('audio_file', document.getElementById('audioFile').files[0]);

                try {
                    this.showProgress('uploadProgress', 'uploadProgressBar', 0, 'Uploading...');
                    
                    const response = await fetch('/upload_voice', {
                        method: 'POST',
                        body: formData
                    });

                    const result = await response.json();
                    
                    if (result.success) {
                        this.showStatus('uploadStatus', 'Voice uploaded successfully!', 'success');
                        form.reset();
                        document.getElementById('audioPreview').classList.add('hidden');
                        this.hideProgress('uploadProgress');
                        this.loadVoices();
                    } else {
                        this.showStatus('uploadStatus', `Upload failed: ${result.message}`, 'error');
                        this.hideProgress('uploadProgress');
                    }
                } catch (error) {
                    this.showStatus('uploadStatus', `Upload error: ${error.message}`, 'error');
                    this.hideProgress('uploadProgress');
                }
            }            generateSpeech() {
                const voiceName = document.getElementById('selectedVoice').value;
                const text = document.getElementById('textInput').value;
                const realtimeMode = document.getElementById('realtimeMode').checked;

                if (!voiceName || !text) {
                    this.showStatus('generateStatus', 'Please select a voice and enter text', 'error');
                    return;
                }

                // Clear previous results
                document.getElementById('generatedAudio').classList.add('hidden');
                document.getElementById('realtimeAudioContainer').classList.add('hidden');
                
                if (realtimeMode) {
                    // Initialize real-time container
                    this.initializeRealtimeContainer();
                    
                    this.sendMessage({
                        type: 'generate_speech_realtime',
                        voice_name: voiceName,
                        text: text
                    });
                } else {
                    this.sendMessage({
                        type: 'generate_speech',
                        voice_name: voiceName,
                        text: text
                    });
                }

                this.showProgress('generateProgress', 'generateProgressBar', 20, 'Starting generation...');
            }

            handleSpeechGenerated(message) {
                this.hideProgress('generateProgress');
                this.showStatus('generateStatus', 'Speech generated successfully!', 'success');
                
                const audioContainer = document.getElementById('generatedAudio');
                const player = document.getElementById('generatedPlayer');
                const downloadLink = document.getElementById('downloadLink');
                
                const audioUrl = `${this.baseUrl}${message.audio_file}`;
                player.src = audioUrl;
                downloadLink.href = audioUrl;
                downloadLink.download = `generated_${message.voice_name}.wav`;
                
                audioContainer.classList.remove('hidden');
            }

            async loadVoices() {
                try {
                    const response = await fetch('/voices');
                    const data = await response.json();
                    
                    if (data.success) {
                        this.voices = data.voices;
                        this.updateVoicesList();
                        this.updateVoiceSelect();
                    }
                } catch (error) {
                    console.error('Error loading voices:', error);
                }
            }

            updateVoiceSelect() {
                const select = document.getElementById('selectedVoice');
                select.innerHTML = '<option value="">Select a voice...</option>';
                
                this.voices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.voice_name;
                    option.textContent = voice.voice_name;
                    select.appendChild(option);
                });
            }

            updateVoicesList() {
                const container = document.getElementById('voicesList');
                
                if (this.voices.length === 0) {
                    container.innerHTML = '<p>No voices available. Upload your first voice sample!</p>';
                    return;
                }

                container.innerHTML = this.voices.map(voice => `
                    <div class="voice-card">
                        <h3>${voice.voice_name}</h3>
                        <p>${voice.metadata?.description || 'No description'}</p>
                        <p><strong>Language:</strong> ${voice.metadata?.language || 'Unknown'}</p>
                        <p><strong>Created:</strong> ${new Date(voice.created_at).toLocaleDateString()}</p>
                        <button class="btn" onclick="app.selectVoiceForGeneration('${voice.voice_name}')">🎤 Use for Generation</button>
                        <button class="btn btn-danger" onclick="app.deleteVoice('${voice.voice_name}')">🗑️ Delete</button>
                    </div>
                `).join('');
            }

            selectVoiceForGeneration(voiceName) {
                document.getElementById('selectedVoice').value = voiceName;
                this.showVoiceDetails(voiceName);
                document.getElementById('generateSection').scrollIntoView({ behavior: 'smooth' });
            }

            async showVoiceDetails(voiceName) {
                const container = document.getElementById('voiceDetails');
                
                if (!voiceName) {
                    container.innerHTML = '<p>Select a voice to see details</p>';
                    return;
                }

                try {
                    const response = await fetch(`/voice/${voiceName}`);
                    const data = await response.json();
                    
                    if (data.success) {
                        const profile = data.voice_profile;
                        const metadata = profile.metadata || {};
                        
                        container.innerHTML = `
                            <h3>${voiceName}</h3>
                            <p><strong>Description:</strong> ${metadata.description || 'No description'}</p>
                            <p><strong>Language:</strong> ${metadata.language || 'Unknown'}</p>
                            <p><strong>Created:</strong> ${new Date(profile.created_at).toLocaleDateString()}</p>
                            <p><strong>File:</strong> ${metadata.original_filename || 'Unknown'}</p>
                        `;
                    }
                } catch (error) {
                    container.innerHTML = '<p>Error loading voice details</p>';
                }
            }

            async deleteVoice(voiceName) {
                if (!confirm(`Are you sure you want to delete voice '${voiceName}'?`)) {
                    return;
                }

                try {
                    const response = await fetch(`/voice/${voiceName}`, {
                        method: 'DELETE'
                    });

                    const result = await response.json();
                    
                    if (result.success) {
                        this.loadVoices();
                    } else {
                        alert(`Failed to delete voice: ${result.message}`);
                    }
                } catch (error) {
                    alert(`Error deleting voice: ${error.message}`);
                }
            }

            showStatus(containerId, message, type) {
                const container = document.getElementById(containerId);
                const statusDiv = document.createElement('div');
                statusDiv.className = `status ${type}`;
                statusDiv.textContent = message;
                
                // Remove existing status
                const existing = container.querySelector('.status');
                if (existing) {
                    existing.remove();
                }
                
                container.appendChild(statusDiv);
                
                // Auto-remove after 5 seconds
                setTimeout(() => {
                    if (statusDiv.parentNode) {
                        statusDiv.remove();
                    }
                }, 5000);
            }

            showProgress(containerId, barId, progress, message) {
                const container = document.getElementById(containerId);
                const bar = document.getElementById(barId);
                
                container.classList.remove('hidden');
                bar.style.width = `${progress}%`;
                bar.textContent = message || `${progress}%`;
            }            updateProgress(containerId, barId, progress, message) {
                const bar = document.getElementById(barId);
                bar.style.width = `${progress}%`;
                bar.textContent = message || `${progress}%`;
            }

            hideProgress(containerId) {
                const container = document.getElementById(containerId);
                container.classList.add('hidden');
            }            // === CHATBOT METHODS ===
            initChatbot() {
                this.currentConversationId = null;
                this.isRecording = false;
                this.audioChunks = [];
                this.mediaRecorder = null;
                this.recordingTimeout = null;
                this.silenceDetector = null;
                this.autoMode = false; // Automatic conversation mode
                this.setupChatEventListeners();
                this.updateChatVoiceSelect();
            }            setupChatEventListeners() {
                // Chatbot provider change
                document.getElementById('chatbotProvider').addEventListener('change', (e) => {
                    this.updateChatbotProvider(e.target.value);
                });

                // New conversation button
                document.getElementById('newConversation').addEventListener('click', () => {
                    this.startNewConversation();
                });

                // Load conversations button
                document.getElementById('loadConversations').addEventListener('click', () => {
                    this.toggleConversationsList();
                });

                // Send message button
                document.getElementById('sendMessage').addEventListener('click', () => {
                    this.sendChatMessage();
                });

                // Voice input button
                document.getElementById('voiceInput').addEventListener('click', () => {
                    this.startVoiceInput();
                });

                // Enter key in chat input
                document.getElementById('chatInput').addEventListener('keypress', (e) => {
                    if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        this.sendChatMessage();
                    }
                });
            }

            updateChatVoiceSelect() {
                const select = document.getElementById('chatVoice');
                select.innerHTML = '<option value="">No voice (text only)</option>';
                
                this.voices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.voice_name;
                    option.textContent = voice.voice_name;
                    select.appendChild(option);
                });            }

            updateChatbotProvider(provider) {
                const aiNameElement = document.getElementById('aiAssistantName');
                const welcomeTextElement = document.getElementById('welcomeText');
                
                if (provider === 'openai') {
                    aiNameElement.textContent = 'OpenAI GPT-3.5:';
                    welcomeTextElement.textContent = 'नमस्ते! I\'m OpenAI GPT-3.5-turbo, ready to chat with you in Hinglish. आप कैसे हैं? How can I help you today?';
                } else if (provider === 'gemini') {
                    aiNameElement.textContent = 'Google Gemini:';
                    welcomeTextElement.textContent = 'नमस्ते! I\'m Google Gemini, ready to chat with you in Hinglish. आप कैसे हैं? How can I help you today?';
                }
                
                // Show status message about provider change
                this.showStatus('chatStatus', `Switched to ${provider === 'openai' ? 'OpenAI GPT-3.5-turbo' : 'Google Gemini'} chatbot`, 'success');
                
                // If there's an active conversation, you might want to restart it or notify the user
                if (this.currentConversationId) {
                    this.showStatus('chatStatus', 'Provider changed. You may want to start a new conversation for consistency.', 'info');
                }
            }

            startNewConversation() {
                this.sendMessage({
                    type: 'start_conversation',
                    title: 'New Hinglish Chat',
                    language: 'hinglish',
                    metadata: { created_from: 'web_interface' }
                });
            }            sendChatMessage() {
                const input = document.getElementById('chatInput');
                const message = input.value.trim();
                const voiceName = document.getElementById('chatVoice').value;
                const chatbotProvider = document.getElementById('chatbotProvider').value;

                if (!message) return;
                if (!this.currentConversationId) {
                    this.showStatus('chatStatus', 'Please start a new conversation first', 'error');
                    return;
                }

                // Clear input
                input.value = '';

                // Add user message to chat
                this.addChatMessage('user', message);

                // Send to server
                this.sendMessage({
                    type: 'chat_message',
                    conversation_id: this.currentConversationId,
                    message: message,
                    voice_name: voiceName,
                    chatbot_provider: chatbotProvider
                });

                this.showProgress('chatProgress', 'chatProgressBar', 20, 'Sending message...');            }            addChatMessage(role, content, audioFile = null) {
                const messagesContainer = document.getElementById('chatMessages');
                const messageDiv = document.createElement('div');
                messageDiv.className = `chat-message ${role}`;

                let audioHtml = '';
                if (audioFile) {
                    // Fix audio file URL - ensure it's a proper HTTP URL
                    let audioUrl = audioFile;                    if (audioFile.startsWith('file:///')) {
                        // Extract just the filename from file:// URL
                        const filename = audioFile.split('/').pop();
                        audioUrl = `${this.baseUrl}/download/${filename}`;
                    } else if (!audioFile.startsWith('http://') && !audioFile.startsWith('https://')) {
                        // If it's a relative path, construct proper server URL
                        const filename = audioFile.split('\\').pop().split('/').pop(); // Handle both / and \ separators
                        audioUrl = `${this.baseUrl}/download/${filename}`;
                    }
                    
                    // Create unique ID for this audio element
                    const audioId = `audio_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
                    audioHtml = `
                        <div class="message-audio">
                            <audio id="${audioId}" controls>
                                <source src="${audioUrl}" type="audio/wav">
                                Your browser does not support the audio element.
                            </audio>
                        </div>
                    `;
                }

                messageDiv.innerHTML = `
                    <div class="message-content">
                        <strong>${role === 'user' ? 'You' : 'AI Assistant'}:</strong> ${content}
                        ${audioHtml}
                    </div>
                `;

                messagesContainer.appendChild(messageDiv);
                messagesContainer.scrollTop = messagesContainer.scrollHeight;

                // Auto-play AI assistant audio responses
                if (audioFile && role === 'assistant') {
                    setTimeout(() => {
                        const audioElement = messageDiv.querySelector('audio');
                        if (audioElement) {
                            this.playAIResponseAndStartRecording(audioElement);
                        }
                    }, 500); // Small delay to ensure audio element is ready
                }

                // Update message count
                const messageCount = messagesContainer.children.length - 1; // Exclude welcome message
                document.getElementById('chatMessageCount').textContent = `${messageCount} messages`;
            }

            toggleConversationsList() {
                const listContainer = document.getElementById('conversationsList');
                const chatContainer = document.getElementById('chatContainer');

                if (listContainer.classList.contains('hidden')) {
                    // Show conversations list
                    this.loadConversations();
                    listContainer.classList.remove('hidden');
                    chatContainer.classList.add('hidden');
                } else {
                    // Hide conversations list
                    listContainer.classList.add('hidden');
                    if (this.currentConversationId) {
                        chatContainer.classList.remove('hidden');
                    }
                }
            }

            loadConversations() {
                this.sendMessage({
                    type: 'list_conversations',
                    limit: 20
                });
            }

            setExample(text) {
                document.getElementById('chatInput').value = text;
            }            startVoiceInput() {
                if (!this.currentConversationId) {
                    this.showStatus('chatStatus', 'Please start a new conversation first', 'error');
                    return;
                }

                if (this.isRecording) {
                    this.stopVoiceRecording();
                    return;
                }

                // Manual voice input (not automatic)
                this.autoMode = false;
                this.startVoiceRecording();
            }

            async startVoiceRecording() {
                try {
                    // Request microphone permission
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    this.audioChunks = [];
                    this.isRecording = true;

                    // Update UI
                    const voiceButton = document.getElementById('voiceInput');
                    voiceButton.textContent = ' Stop';
                    voiceButton.classList.add('recording');
                    this.showStatus('chatStatus', 'Recording... Speak in Hinglish', 'info');

                    // Handle data available
                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                    };

                    // Handle recording stop
                    this.mediaRecorder.onstop = () => {
                        this.processVoiceRecording();
                    };

                    // Start recording
                    this.mediaRecorder.start();

                    // Auto-stop after 30 seconds
                    this.recordingTimeout = setTimeout(() => {
                        if (this.isRecording) {
                            this.stopVoiceRecording();
                        }
                    }, 30000);

                } catch (error) {
                    console.error('Error starting voice recording:', error);
                    this.showStatus('chatStatus', 'Error: Could not access microphone', 'error');
                    this.resetVoiceUI();
                }
            }

            stopVoiceRecording() {
                if (!this.isRecording || !this.mediaRecorder) {
                    return;
                }

                this.isRecording = false;
                this.mediaRecorder.stop();
                
                // Stop all tracks
                this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clear timeout
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                }

                this.showStatus('chatStatus', 'Processing audio...', 'info');
            }

            async processVoiceRecording() {
                try {
                    // Create blob from audio chunks
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    
                    // Convert to base64
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const uint8Array = new Uint8Array(arrayBuffer);
                    const base64Audio = btoa(String.fromCharCode(...uint8Array));

                    // Send to server for speech-to-text
                    this.sendMessage({
                        type: 'speech_to_text',
                        audio_data: base64Audio,
                        format: 'webm',
                        language: 'hinglish'
                    });

                    this.showProgress('chatProgress', 'chatProgressBar', 30, 'Converting speech to text...');

                } catch (error) {
                    console.error('Error processing voice recording:', error);
                    this.showStatus('chatStatus', 'Error processing audio', 'error');
                } finally {
                    this.resetVoiceUI();
                }
            }

            resetVoiceUI() {
                const voiceButton = document.getElementById('voiceInput');
                voiceButton.textContent = ' Voice';
                voiceButton.classList.remove('recording');
                this.isRecording = false;
                this.audioChunks = [];
                
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                    this.recordingTimeout = null;
                }
            }

            // === AUTOMATIC CONVERSATION METHODS ===
            
            async playAIResponseAndStartRecording(audioElement) {
                try {
                    console.log(' Auto-playing AI response...');
                    this.showStatus('chatStatus', ' Playing AI response...', 'info');
                    
                    // Play the audio response
                    await audioElement.play();
                    
                    // Wait for audio to finish playing
                    return new Promise((resolve) => {
                        audioElement.onended = () => {
                            console.log(' AI response finished playing');
                            this.showStatus('chatStatus', ' Ready to listen...', 'info');
                            
                            // Start automatic voice recording after a short delay
                            setTimeout(() => {
                                this.startAutomaticVoiceRecording();
                                resolve();
                            }, 1000); // 1 second delay before starting recording
                        };
                        
                        audioElement.onerror = () => {
                            console.error(' Error playing AI response');
                            this.showStatus('chatStatus', 'Error playing response', 'error');
                            resolve();
                        };
                    });
                    
                } catch (error) {
                    console.error('Error in auto-play:', error);
                    this.showStatus('chatStatus', 'Could not auto-play response', 'error');
                }
            }

            async startAutomaticVoiceRecording() {
                if (!this.currentConversationId) {
                    return;
                }

                try {
                    console.log(' Starting automatic voice recording...');
                    
                    // Request microphone permission
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    this.audioChunks = [];
                    this.isRecording = true;
                    this.autoMode = true;

                    // Update UI for automatic recording
                    const voiceButton = document.getElementById('voiceInput');
                    voiceButton.textContent = ' Auto Recording';
                    voiceButton.classList.add('recording');
                    this.showStatus('chatStatus', ' Auto-recording... Speak now (3s silence stops)', 'info');

                    // Set up silence detection
                    this.setupSilenceDetection(stream);

                    // Handle data available
                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                    };

                    // Handle recording stop
                    this.mediaRecorder.onstop = () => {
                        this.processAutomaticVoiceRecording();
                    };

                    // Start recording
                    this.mediaRecorder.start();

                    // Failsafe: stop after 30 seconds max
                    this.recordingTimeout = setTimeout(() => {
                        if (this.isRecording) {
                            console.log('⏰ Maximum recording time reached');
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 30000);

                } catch (error) {
                    console.error('Error starting automatic voice recording:', error);
                    this.showStatus('chatStatus', 'Error: Could not start automatic recording', 'error');
                    this.resetVoiceUI();
                }
            }

            setupSilenceDetection(stream) {
                try {
                    // Create audio context for silence detection
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    const analyser = audioContext.createAnalyser();
                    
                    analyser.fftSize = 256;
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    
                    source.connect(analyser);
                    
                    let silenceStartTime = null;
                    const silenceThreshold = 30; // Threshold for silence (adjust as needed)
                    const silenceTimeout = 3000; // 3 seconds of silence
                    
                    const checkAudioLevel = () => {
                        if (!this.isRecording) return;
                        
                        analyser.getByteFrequencyData(dataArray);
                        
                        // Calculate average volume
                        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                        
                        if (average < silenceThreshold) {
                            // Silence detected
                            if (silenceStartTime === null) {
                                silenceStartTime = Date.now();
                                console.log(' Silence detected, starting timer...');
                            } else if (Date.now() - silenceStartTime >= silenceTimeout) {
                                console.log(' 3 seconds of silence detected, stopping recording');
                                this.stopAutomaticVoiceRecording();
                                return;
                            }
                        } else {
                            // Sound detected, reset silence timer
                            if (silenceStartTime !== null) {
                                console.log(' Sound detected, resetting silence timer');
                                silenceStartTime = null;
                            }
                        }
                        
                        // Continue checking
                        requestAnimationFrame(checkAudioLevel);
                    };
                    
                    // Start monitoring
                    checkAudioLevel();
                    
                    // Store references for cleanup
                    this.silenceDetector = {
                        audioContext,
                        source,
                        analyser,
                        cleanup: () => {
                            try {
                                source.disconnect();
                                audioContext.close();
                            } catch (e) {
                                console.log('Cleanup warning:', e);
                            }
                        }
                    };
                    
                } catch (error) {
                    console.error('Error setting up silence detection:', error);
                    // Fallback: just use timer-based recording
                    setTimeout(() => {
                        if (this.isRecording) {
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 10000); // 10 seconds fallback
                }
            }

            stopAutomaticVoiceRecording() {
                if (!this.isRecording || !this.mediaRecorder) {
                    return;
                }

                console.log('Stopping automatic voice recording...');
                this.isRecording = false;
                this.mediaRecorder.stop();
                
                // Stop all tracks
                this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clean up silence detector
                if (this.silenceDetector) {
                    this.silenceDetector.cleanup();
                    this.silenceDetector = null;
                }
                
                // Clear timeout
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                }

                this.showStatus('chatStatus', 'Processing your voice...', 'info');
            }

            async processAutomaticVoiceRecording() {
                try {
                    console.log(' Processing automatic voice recording...');
                    
                    // Create blob from audio chunks
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    
                    // Check if we have meaningful audio (not just silence)
                    if (audioBlob.size < 1000) { // Less than 1KB likely means no speech
                        console.log(' Recording too short, likely no speech detected');
                        this.showStatus('chatStatus', 'No speech detected. Try speaking louder.', 'warning');
                        this.resetVoiceUI();
                        return;
                    }
                    
                    // Convert to base64
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const uint8Array = new Uint8Array(arrayBuffer);
                    const base64Audio = btoa(String.fromCharCode(...uint8Array));

                    // Send to server for speech-to-text
                    this.sendMessage({
                        type: 'speech_to_text',
                        audio_data: base64Audio,
                        format: 'webm',
                        language: 'hinglish'
                    });

                    this.showProgress('chatProgress', 'chatProgressBar', 30, 'Converting speech to text...');

                } catch (error) {
                    console.error('Error processing automatic voice recording:', error);
                    this.showStatus('chatStatus', 'Error processing voice', 'error');
                } finally {
                    this.resetVoiceUI();
                }
            }

            handleSpeechToTextResult(message) {
                this.hideProgress('chatProgress');
                
                if (message.transcript && message.transcript.trim()) {
                    console.log(' Speech transcribed:', message.transcript);
                    
                    // In automatic mode, send the message immediately
                    if (this.autoMode) {
                        // Add transcribed text as user message and send immediately
                        this.addChatMessage('user', message.transcript);
                        
                        // Send to server for AI response
                        const voiceName = document.getElementById('chatVoice').value;
                        this.sendMessage({
                            type: 'chat_message',
                            conversation_id: this.currentConversationId,
                            message: message.transcript,
                            voice_name: voiceName
                        });
                        
                        const confidence = Math.round(message.confidence * 100);
                        this.showStatus('chatStatus', `Message sent! Confidence: ${confidence}%`, 'success');
                        this.showProgress('chatProgress', 'chatProgressBar', 20, 'Getting AI response...');
                    } else {
                        // Manual mode: add to input for editing
                        const chatInput = document.getElementById('chatInput');
                        const currentText = chatInput.value.trim();
                        const newText = currentText ? `${currentText} ${message.transcript}` : message.transcript;
                        chatInput.value = newText;
                        
                        const confidence = Math.round(message.confidence * 100);
                        this.showStatus('chatStatus', `Voice transcribed! Confidence: ${confidence}%`, 'success');
                        chatInput.focus();
                        
                        if (confirm('Send this message now?\n\n"' + message.transcript + '"')) {
                            this.sendChatMessage();
                        }
                    }
                } else {
                    this.showStatus('chatStatus', 'Could not understand speech. Please try again.', 'error');
                }
                
                // Reset auto mode flag
                this.autoMode = false;
            }

            // Modified existing method to handle both manual and automatic modes
            startVoiceInput() {
                if (!this.currentConversationId) {
                    this.showStatus('chatStatus', 'Please start a new conversation first', 'error');
                    return;
                }

                if (this.isRecording) {
                    this.stopVoiceRecording();
                    return;
                }

                // Manual voice input (not automatic)
                this.autoMode = false;
                this.startVoiceRecording();
            }

            // === AUTOMATIC CONVERSATION METHODS ===
            
            async playAIResponseAndStartRecording(audioElement) {
                try {
                    console.log(' Auto-playing AI response...');
                    this.showStatus('chatStatus', ' Playing AI response...', 'info');
                    
                    // Play the audio response
                    await audioElement.play();
                    
                    // Wait for audio to finish playing
                    return new Promise((resolve) => {
                        audioElement.onended = () => {
                            console.log(' AI response finished playing');
                            this.showStatus('chatStatus', ' Ready to listen...', 'info');
                            
                            // Start automatic voice recording after a short delay
                            setTimeout(() => {
                                this.startAutomaticVoiceRecording();
                                resolve();
                            }, 1000); // 1 second delay before starting recording
                        };
                        
                        audioElement.onerror = () => {
                            console.error(' Error playing AI response');
                            this.showStatus('chatStatus', 'Error playing response', 'error');
                            resolve();
                        };
                    });
                    
                } catch (error) {
                    console.error('Error in auto-play:', error);
                    this.showStatus('chatStatus', 'Could not auto-play response', 'error');
                }
            }

            async startAutomaticVoiceRecording() {
                if (!this.currentConversationId) {
                    return;
                }

                try {
                    console.log(' Starting automatic voice recording...');
                    
                    // Request microphone permission
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    this.audioChunks = [];
                    this.isRecording = true;
                    this.autoMode = true;

                    // Update UI for automatic recording
                    const voiceButton = document.getElementById('voiceInput');
                    voiceButton.textContent = ' Auto Recording';
                    voiceButton.classList.add('recording');
                    this.showStatus('chatStatus', ' Auto-recording... Speak now (3s silence stops)', 'info');

                    // Set up silence detection
                    this.setupSilenceDetection(stream);

                    // Handle data available
                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                    };

                    // Handle recording stop
                    this.mediaRecorder.onstop = () => {
                        this.processAutomaticVoiceRecording();
                    };

                    // Start recording
                    this.mediaRecorder.start();

                    // Failsafe: stop after 30 seconds max
                    this.recordingTimeout = setTimeout(() => {
                        if (this.isRecording) {
                            console.log(' Maximum recording time reached');
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 30000);

                } catch (error) {
                    console.error('Error starting automatic voice recording:', error);
                    this.showStatus('chatStatus', 'Error: Could not start automatic recording', 'error');
                    this.resetVoiceUI();
                }
            }

            setupSilenceDetection(stream) {
                try {
                    // Create audio context for silence detection
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    const analyser = audioContext.createAnalyser();
                    
                    analyser.fftSize = 256;
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    
                    source.connect(analyser);
                    
                    let silenceStartTime = null;
                    const silenceThreshold = 30; // Threshold for silence (adjust as needed)
                    const silenceTimeout = 3000; // 3 seconds of silence
                    
                    const checkAudioLevel = () => {
                        if (!this.isRecording) return;
                        
                        analyser.getByteFrequencyData(dataArray);
                        
                        // Calculate average volume
                        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                        
                        if (average < silenceThreshold) {
                            // Silence detected
                            if (silenceStartTime === null) {
                                silenceStartTime = Date.now();
                                console.log(' Silence detected, starting timer...');
                            } else if (Date.now() - silenceStartTime >= silenceTimeout) {
                                console.log(' 3 seconds of silence detected, stopping recording');
                                this.stopAutomaticVoiceRecording();
                                return;
                            }
                        } else {
                            // Sound detected, reset silence timer
                            if (silenceStartTime !== null) {
                                console.log(' Sound detected, resetting silence timer');
                                silenceStartTime = null;
                            }
                        }
                        
                        // Continue checking
                        requestAnimationFrame(checkAudioLevel);
                    };
                    
                    // Start monitoring
                    checkAudioLevel();
                    
                    // Store references for cleanup
                    this.silenceDetector = {
                        audioContext,
                        source,
                        analyser,
                        cleanup: () => {
                            try {
                                source.disconnect();
                                audioContext.close();
                            } catch (e) {
                                console.log('Cleanup warning:', e);
                            }
                        }
                    };
                    
                } catch (error) {
                    console.error('Error setting up silence detection:', error);
                    // Fallback: just use timer-based recording
                    setTimeout(() => {
                        if (this.isRecording) {
                            this.stopAutomaticVoiceRecording();
                        }
                    }, 10000); // 10 seconds fallback
                }
            }

            stopAutomaticVoiceRecording() {
                if (!this.isRecording || !this.mediaRecorder) {
                    return;
                }

                console.log(' Stopping automatic voice recording...');
                this.isRecording = false;
                this.mediaRecorder.stop();
                
                // Stop all tracks
                this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clean up silence detector
                if (this.silenceDetector) {
                    this.silenceDetector.cleanup();
                    this.silenceDetector = null;
                }
                
                // Clear timeout
                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                }                this.showStatus('chatStatus', 'Processing your voice...', 'info');
            }

            // === MISSING WEBSOCKET HANDLER METHODS ===

            handleConversationStarted(message) {
                console.log(' Conversation started:', message);
                if (message.conversation_id) {
                    this.currentConversationId = message.conversation_id;
                    this.showStatus('chatStatus', 'New conversation started', 'success');
                    
                    // Show chat interface
                    document.getElementById('chatContainer').classList.remove('hidden');
                    document.getElementById('conversationsList').classList.add('hidden');
                    
                    // Focus on chat input
                    document.getElementById('chatInput').focus();
                }
            }            handleChatResponse(message) {
                console.log(' Chat response received:', message);
                
                // Handle WebSocket chat response format
                if (message.assistant_message) {
                    // Add user message to chat if provided
                    if (message.user_message) {
                        this.addChatMessage('user', message.user_message);
                    }
                    
                    // Add AI response to chat with audio
                    this.addChatMessage('assistant', message.assistant_message, message.audio_file);
                      // Handle automatic mode - play audio and start recording
                    if (this.autoMode && message.audio_file) {
                        // Fix audio file URL for automatic playback
                        let audioUrl = message.audio_file;                        if (message.audio_file.startsWith('file:///')) {
                            const filename = message.audio_file.split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        } else if (!message.audio_file.startsWith('http://') && !message.audio_file.startsWith('https://')) {
                            const filename = message.audio_file.split('\\').pop().split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        }
                        const audioElement = new Audio(audioUrl);
                        this.playAIResponseAndStartRecording(audioElement);
                    }
                    
                    this.showStatus('chatStatus', 'Response received', 'success');
                } else if (message.success && message.response) {
                    // Legacy format support
                    this.addChatMessage('ai', message.response, message.audio_url);
                      if (this.autoMode && message.audio_url) {
                        // Fix audio file URL for automatic playback
                        let audioUrl = message.audio_url;                        if (message.audio_url.startsWith('file:///')) {
                            const filename = message.audio_url.split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        } else if (!message.audio_url.startsWith('http://') && !message.audio_url.startsWith('https://')) {
                            const filename = message.audio_url.split('\\').pop().split('/').pop();
                            audioUrl = `${this.baseUrl}/download/${filename}`;
                        }
                        const audioElement = new Audio(audioUrl);
                        this.playAIResponseAndStartRecording(audioElement);
                    }
                    
                    this.showStatus('chatStatus', 'Response received', 'success');
                } else {
                    this.showStatus('chatStatus', message.message || 'Failed to get response', 'error');
                }
                
                this.hideProgress('chatProgress');            }

            handleConversationsList(message) {
                console.log('📋 Conversations list received:', message);
                
                const container = document.getElementById('conversationsContainer');
                const conversations = message.conversations || [];
                
                if (conversations.length > 0) {
                    container.innerHTML = `
                        <div class="conversations-header">
                            <h3>📋 Previous Conversations (${conversations.length})</h3>
                            <button class="btn btn-primary" onclick="app.toggleConversationsList()">
                                ← Back to Chat
                            </button>
                        </div>
                        <div class="conversations-list">                            ${conversations.map(conv => `
                                <div class="conversation-item" onclick="app.loadConversationDetails('${conv.id}')">
                                    <div class="conversation-header">
                                        <h4>${conv.title || 'Untitled Conversation'}</h4>
                                        <span class="conversation-date">${new Date(conv.created_at).toLocaleDateString('en-IN', {
                                            year: 'numeric',
                                            month: 'short',
                                            day: 'numeric',
                                            hour: '2-digit',
                                            minute: '2-digit'
                                        })}</span>
                                    </div>
                                    <div class="conversation-preview">
                                        <p class="last-message">${(conv.last_message || 'No messages yet').substring(0, 100)}${(conv.last_message || '').length > 100 ? '...' : ''}</p>
                                        <span class="message-count">${conv.message_count || 0} messages</span>
                                    </div>
                                    <div class="conversation-actions">
                                        <button class="btn btn-small btn-primary" onclick="event.stopPropagation(); app.loadConversationDetails('${conv.id}')">
                                            💬 Continue
                                        </button>
                                        <button class="btn btn-small btn-danger" onclick="event.stopPropagation(); app.deleteConversation('${conv.id}')">
                                            🗑️ Delete
                                        </button>
                                    </div>
                                </div>
                            `).join('')}
                        </div>
                    `;
                } else {
                    container.innerHTML = `
                        <div class="conversations-header">
                            <h3>📋 No Previous Conversations</h3>
                            <button class="btn btn-primary" onclick="app.toggleConversationsList()">
                                ← Back to Chat
                            </button>
                        </div>
                        <div class="no-conversations">
                            <p>No previous conversations found.</p>
                            <p>Start a new conversation to begin chatting!</p>
                        </div>
                    `;
                }
                
                this.showStatus('chatStatus', `Found ${conversations.length} previous conversations`, 'success');
            }            handleConversationDetails(message) {
                console.log('💬 Loading conversation details:', message);
                
                // Hide the loading progress bar first
                this.hideProgress('chatProgress');
                
                if (!message.conversation || !message.messages) {
                    this.showStatus('chatStatus', 'Error loading conversation details', 'error');
                    return;
                }
                  const conversation = message.conversation;
                const messages = message.messages;
                
                // Set current conversation
                this.currentConversationId = conversation.id;
                
                // Update conversation info
                document.getElementById('chatMessageCount').textContent = `${messages.length} messages`;
                
                // Clear and rebuild messages
                const messagesContainer = document.getElementById('chatMessages');
                messagesContainer.innerHTML = `
                    <div class="chat-message assistant welcome">
                        <div class="message-content">
                            <strong>📋 Loaded Conversation:</strong> ${conversation.title || 'Previous Chat'}
                            <br><small>Started: ${new Date(conversation.created_at).toLocaleString('en-IN')}</small>
                        </div>
                    </div>
                `;
                
                // Add all messages from the conversation
                messages.forEach(msg => {
                    const role = msg.role === 'user' ? 'user' : 'assistant';
                    const content = msg.content || msg.message_text;
                    const audioFile = msg.audio_file || null;
                    
                    this.addChatMessage(role, content, audioFile);
                });
                
                // Show chat container and hide conversations list
                document.getElementById('chatContainer').classList.remove('hidden');
                document.getElementById('conversationsList').classList.add('hidden');
                
                // Scroll to bottom
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
                
                this.showStatus('chatStatus', `Loaded conversation with ${messages.length} messages`, 'success');
            }

            loadConversationDetails(conversationId) {
                console.log('🔍 Loading conversation details for:', conversationId);
                
                this.sendMessage({
                    type: 'get_conversation',
                    conversation_id: conversationId
                });
                
                this.showProgress('chatProgress', 'chatProgressBar', 30, 'Loading conversation...');
            }

            deleteConversation(conversationId) {
                if (!confirm('Are you sure you want to delete this conversation? This action cannot be undone.')) {
                    return;
                }
                
                console.log('🗑️ Deleting conversation:', conversationId);
                
                this.sendMessage({
                    type: 'delete_conversation',
                    conversation_id: conversationId
                });
                
                this.showStatus('chatStatus', 'Deleting conversation...', 'info');
                  // Reload conversations list
                setTimeout(() => {
                    this.loadConversations();
                }, 1000);
            }

            handleRealtimeComplete(message) {
                console.log(' Realtime generation complete:', message);
                
                if (message.success) {
                    this.showStatus('generateStatus', 'Speech generated successfully!', 'success');
                    
                    if (message.audio_url) {
                        // Show audio player
                        const audioPlayer = document.getElementById('generatedAudio');
                        const audioContainer = document.getElementById('audioResult');
                        
                        audioPlayer.src = message.audio_url;
                        audioContainer.classList.remove('hidden');
                        
                        // Auto-play if enabled
                        if (this.autoPlayEnabled) {
                            audioPlayer.play();
                        }
                    }
                } else {
                    this.showStatus('generateStatus', message.message || 'Generation failed', 'error');
                }
                
                this.hideProgress('generateProgress');
            }

            handleAudioChunk(message) {
                console.log(' Audio chunk received:', message);
                // Handle streaming audio chunks if needed for realtime playback
                if (message.chunk_data && this.streamingAudio) {
                    // Implementation for streaming audio playback
                    // This would be used for realtime audio streaming
                }
            }

            // Helper method to load a specific conversation
            loadConversation(conversationId) {
                this.sendMessage({
                    type: 'get_conversation',
                    conversation_id: conversationId
                });
            }
        }

        // Initialize app
        const app = new VoiceCloningApp();

        // Example text function for Hinglish samples
        function setExampleText(exampleNumber) {
            const textInput = document.getElementById('textInput');
            const examples = {
                1: "नमस्ते दोस्त, यहाँ तो मौसम बिल्कुल साफ़ और क्लियर है, आप बताओ कि वहाँ हाल चाल कैसा है। आशा है मेरी कि आपका हाल भी ठीक ही होगा। and i really do hope that the weather is fine at your end.",
                2: "आज का दिन बहुत अच्छा है यार, weather is really nice today. मैंने सुबह जॉगिंग की and then had a great breakfast. अब तो बस office जाना है और फिर evening में friends के साथ movie देखने जाना है।",
                3: "Hi भाई, कैसे हो आप? I hope सब कुछ ठीक चल रहा है। मुझे बताना था कि tomorrow की meeting postpone हो गई है, so we can reschedule it for next week. Let me know जब आपका time free हो।"
            };
            
            if (examples[exampleNumber]) {
                textInput.value = examples[exampleNumber];
                textInput.focus();
            }
        }
    </script>
</body>
</html>
